{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AtaxxZero\n",
    "## This algorithm tried to reimplement AlphaGo Zero for Ataxx\n",
    "## however, the computation to train an AI from scratch can be too heavy, given my skills of code optimization and hardware limitation\n",
    "## therefore, minor adjustments are made to the algorithms to make it plausible for this algorithm to give a rather satisfactory result in an acceptable period.\n",
    "\n",
    "### modifications:\n",
    "1. One major difference between AlphaGo Zero and Ataxx Zero is that Ataxx Zero relies __one engineered value function__. From the beginning of the training, the q value of each node is a combination of q from the hybrid network and a greedy function (output is monotone increasing with regard to difference of piece no. of each player).\n",
    "2. Another major modification is Ataxx Zero apply MCTS to a __very shallow depth, currently being 3__. This change significantly reduce the searching time, thus accelerate training greatly.\n",
    "3. The combination of 3 layer MCTS and an engineered value function guarantees a good performance of the algorithm in even before training, i.e. hybrid network output random probability and value. The behavior of Ataxx Zero before training should __resemble an impaired MinMax Searching with a depth of 3__. From a practical perspective, it wins 90% of the game with a greedy player(which attempts to maximize no.my_piece - no.opponent's_piece). With reinforcement learning, the algorithm is expected to behave better.\n",
    "4. When actually applied in game, I plan to reduce the searching depth to 2 to further improve the speed, but expect the algorithm to work better than itself before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "from Cython.Compiler.Options import directive_scopes, directive_types\n",
    "directive_types['linetrace'] = True\n",
    "directive_types['binding'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "import line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import importlib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "from multiprocessing import Queue, Pool, Process\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from math import sqrt, log, exp\n",
    "from numpy import unravel_index\n",
    "from random import choice, random, sample\n",
    "from operator import itemgetter\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Reshape, Lambda\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LocallyConnected2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AlphaDropout, ConvLSTM2D, AvgPool2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import add, concatenate, multiply, Multiply\n",
    "from keras.initializers import VarianceScaling, RandomUniform\n",
    "from keras.optimizers import Adam, SGD, rmsprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.engine.topology import Container\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.callbacks import Callback, ReduceLROnPlateau, LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_keras_backend(backend):\n",
    "    os.environ['KERAS_BACKEND'] = backend\n",
    "    importlib.reload(K)\n",
    "    K.set_image_dim_ordering('th')\n",
    "    assert K.backend() == backend\n",
    "\n",
    "def set_omp_threads(n):\n",
    "    n = str(n)\n",
    "    os.environ['OMP_NUM_THREADS'] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "set_keras_backend('tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rot_policy_dict():\n",
    "    augment_dict = {}\n",
    "    rot_m_0 = np.array([[0, -1], [1, 0]]) \n",
    "    center = np.array([3, 3])\n",
    "    for is_flip in [False, True]:\n",
    "        for rot_time in range(4):\n",
    "            if not (is_flip == False and rot_time == 0):\n",
    "                tmp_dict = {}\n",
    "                # get rot matrix\n",
    "                rot_m = np.eye(2)\n",
    "                for i in range(rot_time):\n",
    "                    rot_m = rot_m_0.dot(rot_m)\n",
    "\n",
    "                for r in range(7):\n",
    "                    for c in range(7):\n",
    "                        for dr in range(-2, 3):\n",
    "                            for dc in range(-2, 3):\n",
    "                                start = np.array([r, c])\n",
    "                                end = np.array([r+dr, c+dc])\n",
    "                                if (dr != 0 or dc != 0) and \\\n",
    "                                    (start[0] < 7 and start[0] >= 0) and (start[1] < 7 and start[1] >= 0):\n",
    "                                    new_start = (start - center)\n",
    "                                    new_end = (end - center)\n",
    "                                    if is_flip:\n",
    "                                        new_start[1] = -new_start[1]\n",
    "                                        new_end[1] = -new_end[1]\n",
    "                                    new_start = rot_m.dot(new_start) + center\n",
    "                                    new_end = rot_m.dot(new_end) + center\n",
    "                                    tmp_dict[(tuple(start), tuple(end))] = (tuple(new_start), tuple(new_end))\n",
    "                augment_dict[(is_flip, rot_time)] = tmp_dict\n",
    "    return augment_dict\n",
    "augment_dict = get_rot_policy_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_policy(data, is_flip, rot_time):\n",
    "    if is_flip == False and rot_time == 0:\n",
    "        return data\n",
    "    \n",
    "    global policy_dict, policy_list, augment_dict\n",
    "    out = np.zeros_like(data)\n",
    "    for i in range(792):\n",
    "        tmp_data = data[i]\n",
    "        if tmp_data > 0:\n",
    "            move = policy_list[i]\n",
    "            move_after_rot = augment_dict[(is_flip, rot_time)][move]\n",
    "            i_after_rot = policy_dict[move_after_rot]\n",
    "            out[i_after_rot] = tmp_data\n",
    "    return out\n",
    "            \n",
    "def augment_data(train_data):\n",
    "    out = []\n",
    "    # input is a list for follows\n",
    "    feature_map = train_data[0]\n",
    "    action_mask = train_data[1]\n",
    "    frequency_map = train_data[2]\n",
    "    value = train_data[3]\n",
    "    \n",
    "    # do 7 times augmentation\n",
    "    for is_flip in [False, True]:\n",
    "        for rot_time in range(4):\n",
    "            # do feature map augmentation\n",
    "            if is_flip:\n",
    "                tmp_feature_map = np.fliplr(feature_map)\n",
    "            tmp_feature_map = np.rot90(feature_map, k=rot_time, axes=(1, 2))\n",
    "            # augment two policy related data\n",
    "            tmp_action_mask = augment_policy(action_mask, is_flip, rot_time)\n",
    "            tmp_frequency_map = augment_policy(frequency_map, is_flip, rot_time)\n",
    "            # append them to out\n",
    "            out.append([tmp_feature_map, tmp_action_mask, tmp_frequency_map, value])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## might be a bit of ugly, but it's really efficient to isolate functions that can be accelerated by cython and jit\n",
    "1. all the dictionary lookup and creation are all integrated in the following cell, which at least reduce the running time for 40%\n",
    "2. memoryview in cython is a strong weapon in terms of algorithm speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "# -a -f --compile-args=-DCYTHON_TRACE=1\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "\n",
    "def get_policy_dict_list():\n",
    "    index=0\n",
    "    policy_dict = {}\n",
    "    policy_list = []\n",
    "    for r in range(7):\n",
    "        for c in range(7):\n",
    "            for dr in range(-2, 3):\n",
    "                for dc in range(-2, 3):\n",
    "                    new_r = r + dr\n",
    "                    new_c = c + dc\n",
    "                    if (dr != 0 or dc != 0) and (new_r < 7 and new_r >= 0) and (new_c < 7 and new_c >= 0):\n",
    "                        policy_dict[((r, c), (new_r, new_c))] = index\n",
    "                        policy_list.append(((r, c), (new_r, new_c)))\n",
    "                        index += 1\n",
    "    return policy_dict, policy_list\n",
    "\n",
    "policy_dict, policy_list = get_policy_dict_list()\n",
    "\n",
    "# this is for expand last two lines\n",
    "def assign_children(children, np.float32_t[:] p_array):\n",
    "    for move in children:\n",
    "        children[move] = np.float32(p_array[policy_dict[move]])\n",
    "\n",
    "cdef class Ataxx:\n",
    "    cdef public np.int8_t[:, :] data\n",
    "\n",
    "    def __init__(self, board=None):\n",
    "        if board is None:                  # if there is no initialization given\n",
    "            self.data = np.zeros((7, 7), dtype=np.int8)   # then generate a board with starting init, and black(-1) takes first turn\n",
    "            self.data[0, 0] = -1           \n",
    "            self.data[6, 6] = -1\n",
    "            self.data[0, 6] = 1\n",
    "            self.data[6, 0] = 1\n",
    "        else:\n",
    "            self.data = board.copy()\n",
    "            \n",
    "    def reset(self, board=None):\n",
    "        if board is None:\n",
    "            self.data = np.zeros((7, 7), dtype=np.int8)\n",
    "            self.data[0, 0] = -1           \n",
    "            self.data[6, 6] = -1\n",
    "            self.data[0, 6] = 1\n",
    "            self.data[6, 0] = 1\n",
    "        else:\n",
    "            self.data = board.copy()\n",
    "        \n",
    "    def get_feature_map(self, turn, move):\n",
    "        cdef int j, k\n",
    "        cdef np.int8_t[:, :, :] out = np.zeros((6, 9, 9), dtype=np.int8)\n",
    "        # define 1 edge\n",
    "        \n",
    "        # edge\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if j == 0 or j == 8 or k == 0 or k == 8:\n",
    "                    out[0, j, k] = 1\n",
    "         \n",
    "        # my pieces\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if j > 0 and j < 8 and k > 0 and k < 8:\n",
    "                    if self.data[j-1, k-1] == turn:\n",
    "                        out[1, j, k] = 1\n",
    "        \n",
    "        # op pieces\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if j > 0 and j < 8 and k > 0 and k < 8:\n",
    "                    if self.data[j-1, k-1] == -turn:\n",
    "                        out[2, j, k] = 1\n",
    "         \n",
    "        # last move\n",
    "        if not move is None:               \n",
    "            out[3, move[0][0]+1, move[0][1]+1] = 1\n",
    "            out[4, move[1][0]+1, move[1][1]+1] = 1\n",
    "            \n",
    "        # whose first\n",
    "        if turn == -1:\n",
    "            for j in range(9):\n",
    "                for k in range(9):\n",
    "                    out[5, j, k] = 1\n",
    "        return np.array(out)\n",
    "    \n",
    "    def plot(self, is_next_move=False, turn=None):                        # plot the board\n",
    "        image = self.data.copy()\n",
    "        if is_next_move:\n",
    "            if turn not in [-1, 1]:\n",
    "                raise ValueError(\"Turn must be -1 or 1, or Must input a turn for next moves\")\n",
    "            else:\n",
    "                next_moves = self.get_moves(turn)\n",
    "                if len(next_moves) == 0:\n",
    "                    raise ValueError(\"Game is over already\")\n",
    "                next_pos = list(zip(*next_moves))[1]\n",
    "                for pos in next_pos:\n",
    "                    image[pos] = turn / 2\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.xticks(range(7), range(7))\n",
    "        plt.yticks(range(7), range(7))\n",
    "        plt.show()\n",
    "                \n",
    "    def is_valid(self, turn, pos):\n",
    "        cdef int dr, dc, r = pos[0], c = pos[1], new_r, new_c\n",
    "        if self.data[r, c] != 0:\n",
    "            return False\n",
    "        else:\n",
    "            for dr in range(-2, 3):\n",
    "                for dc in range(-2, 3):\n",
    "                    new_r = r+dr\n",
    "                    new_c = c+dc\n",
    "                    if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and self.data[new_r, new_c] == turn:\n",
    "                        return True\n",
    "            return False \n",
    "        \n",
    "    def get_moves(self, turn, return_node_info=False):\n",
    "        cdef int r, c, dr, dc, new_r, new_c\n",
    "        cdef np.int8_t[:] action_mask = np.zeros(792, dtype=np.int8)\n",
    "        next_moves = []\n",
    "        corr_dict = {}\n",
    "        children_dict = {}\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                has_duplicate_move = False      # move within the radius of one of another friendly piece is called\n",
    "                if self.is_valid(turn, (r, c)): # duplicate move\n",
    "                    for dr in range(-2, 3):\n",
    "                        for dc in range(-2, 3):\n",
    "                            new_r = r+dr\n",
    "                            new_c = c+dc\n",
    "                            if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and self.data[new_r, new_c] == turn:\n",
    "                                if abs(dr) <= 1 and abs(dc) <=1:\n",
    "                                    if has_duplicate_move: \n",
    "                                        cur_move = ((new_r, new_c), (r, c))\n",
    "                                        corr_dict[cur_move] = dup_move\n",
    "                                        # update action mask\n",
    "                                        if return_node_info: \n",
    "                                            action_mask[policy_dict[cur_move]] = 1\n",
    "                                    elif self.data[new_r, new_c] == turn:\n",
    "                                        dup_move = ((new_r, new_c), (r, c))\n",
    "                                        next_moves.append(dup_move) \n",
    "                                        has_duplicate_move = True\n",
    "                                        # preparing children nodes and action mask\n",
    "                                        if return_node_info: \n",
    "                                            children_dict[dup_move] = None\n",
    "                                            action_mask[policy_dict[dup_move]] = 1\n",
    "                                elif self.data[new_r, new_c] == turn:\n",
    "                                    cur_move = ((new_r, new_c), (r, c))\n",
    "                                    next_moves.append(cur_move) \n",
    "                                    # preparing children nodes and action mask\n",
    "                                    if return_node_info:\n",
    "                                        children_dict[cur_move] = None\n",
    "                                        action_mask[policy_dict[cur_move]] = 1\n",
    "                                else:\n",
    "                                    continue\n",
    "        if return_node_info:\n",
    "            return next_moves, corr_dict, children_dict, np.array(action_mask)\n",
    "        else:\n",
    "            return next_moves\n",
    "    \n",
    "    def get_greedy_move(self, turn, moves=None):\n",
    "        cdef int x0, y0, x1, y1, dr, dc, tmp_score, best_score = -50\n",
    "        # get all possible moves if not provided\n",
    "        if moves is None:\n",
    "            moves, corr_dict, _, _ = self.get_moves(turn, return_node_info=True)\n",
    "            for item in corr_dict:\n",
    "                moves.append(item)\n",
    "        \n",
    "        if len(moves) == 0:\n",
    "            raise ValueError('No Possible Moves')\n",
    "        \n",
    "        best_moves = []\n",
    "        # calculate greedy move\n",
    "        for (x0, y0), (x1, y1) in moves:\n",
    "            tmp_score = 0\n",
    "            if abs(x0-x1) <= 1 and abs(y0-y1) <= 1:\n",
    "                tmp_score += 1\n",
    "            for dr in range(-1, 2):\n",
    "                for dc in range(-1, 2):\n",
    "                    try:\n",
    "                        if x1+dr >= 0 and y1+dc >= 0:\n",
    "                            tmp_score += self.data[x1+dr, y1+dc] == -turn\n",
    "                    except:\n",
    "                        pass\n",
    "            if tmp_score > best_score:\n",
    "                best_moves = [((x0, y0), (x1, y1))]\n",
    "                best_score = tmp_score\n",
    "            elif tmp_score == best_score:\n",
    "                best_moves.append(((x0, y0), (x1, y1)))\n",
    "        return choice(best_moves)\n",
    "        \n",
    "    def move_to(self, turn, pos0, pos1):\n",
    "        cdef int dr, dc, x0 = pos0[0], y0 = pos0[1], x1 = pos1[0], y1 = pos1[1]\n",
    "        \n",
    "        if not self.is_valid(turn, pos1):\n",
    "            raise ValueError(\"This move: \" + str((pos0, pos1)) + \" of turn: \" + str(turn) + \" is invalid\") \n",
    "        elif self.data[x0, y0] != turn:\n",
    "            raise ValueError(\"The starting position is not your piece\")\n",
    "        else:\n",
    "            self.data[x1, y1] = turn\n",
    "            if abs(x0 - x1) > 1 or abs(y0 - y1) > 1:   # jump move\n",
    "                self.data[x0, y0] = 0\n",
    "\n",
    "            for dr in range(-1, 2):                  # infection mode!!!!\n",
    "                for dc in range(-1, 2):\n",
    "                    if x1+dr >= 0 and y1+dc >= 0 and x1+dr < 7 and y1+dc < 7:\n",
    "                        if self.data[x1+dr, y1+dc] == -turn:  # convert any piece of the opponent to 'turn'\n",
    "                            self.data[x1+dr, y1+dc] = turn\n",
    "    @staticmethod                       \n",
    "    def get_manual_q(int turn, np.int8_t[:, :] board):\n",
    "        '''consider linear growth of win prob with regard to n_diff\n",
    "        when diff >= 10, the slope grow a bit\n",
    "        when diff >= 35, consider win prob close to 1 or -1\n",
    "        ''' \n",
    "        cdef int r, c, turn_no = 0, op_no = 0\n",
    "        cdef float max1=0.2, max2=0.9, max3=0.95, diff, sign\n",
    "        # get no diff of turns\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                if board[r, c] == turn:\n",
    "                    turn_no += 1\n",
    "                elif board[r, c] == -turn:\n",
    "                    op_no += 1\n",
    "        diff = turn_no - op_no\n",
    "        sign = diff\n",
    "        diff = abs(diff)\n",
    "        if diff < 10:\n",
    "            diff = diff * max1 / 10\n",
    "        elif diff < 35:\n",
    "            diff = (max2-max1)/25*(diff-10)+max1\n",
    "        else:\n",
    "            diff = max3\n",
    "\n",
    "        if sign < 0:\n",
    "            return -diff\n",
    "        else:\n",
    "            return diff\n",
    "    \n",
    "    def evaluate(self, turn, this_turn, max_score=1, min_score=0.001):\n",
    "        cdef int r, c, turn_no=0, op_no=0\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                if self.data[r, c] == turn:\n",
    "                    turn_no += 1\n",
    "                elif self.data[r, c] == -turn:\n",
    "                    op_no += 1\n",
    "        if len(self.get_moves(this_turn)) == 0:# if one of them can no longer move, count and end\n",
    "            if turn_no > op_no:\n",
    "                return max_score\n",
    "            else:\n",
    "                return -max_score\n",
    "        else:\n",
    "            value = turn_no - op_no\n",
    "        return value * min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def for_node(c, parent_n_visit, n_visit, p, q):\n",
    "    return c * p * sqrt(parent_n_visit) / (n_visit + 1) - q / (n_visit + 1) \n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def get_q(init_q, manual_q):\n",
    "    '''Manual_q and init_q are both an estimation for the q value\n",
    "    It seems that considering init_q to be a rectification will not lead to good result'''\n",
    "    if abs(manual_q) >= 0.9:\n",
    "        return manual_q * 0.9 + init_q * 0.1\n",
    "    elif abs(init_q) < 0.10:\n",
    "        return manual_q * 0.7 + init_q * 0.3\n",
    "    elif abs(init_q) > 0.20:\n",
    "        return manual_q * 0.3 + init_q * 0.7\n",
    "    elif abs(init_q) > 0.30:\n",
    "        return manual_q * 0.1 + init_q * 0.9\n",
    "    else:\n",
    "        return manual_q * 0.5 + init_q * 0.5\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def recover_q(q, manual_q):\n",
    "    '''manual q is the initial guess for win ratio\n",
    "    while init q is the rectification'''\n",
    "    return q\n",
    "\n",
    "class TreeNode():\n",
    "    def __init__(self, parent, p=0.0):\n",
    "        self._parent = parent\n",
    "        self._children = {} # a dictionary of action:node\n",
    "        self._corr_dict = {} # a dictionary for duplicated moves\n",
    "        self._n_visit = 0\n",
    "        # from the parent perspective\n",
    "        self._q = 0.0\n",
    "        self._manual_q = -5 # manually deviced q\n",
    "        self._init_q = -5 # learnt q\n",
    "        self._p = p\n",
    "        self._action_mask = None\n",
    "        self._feature_map = None\n",
    "        self._board = None\n",
    "        self._is_expanded = False\n",
    "        self._prev_move = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        out = \"_n_visit: {}, _q: {}, _p: {}, _children: \\n{}\".format(\\\n",
    "                self._n_visit, self._q, self._p, self._children)\n",
    "        return out\n",
    "    \n",
    "    def get_start_q(self):\n",
    "        assert self._init_q != -5 and self._manual_q != -5\n",
    "        assert self._q == 0\n",
    "        self._q = get_q(self._init_q, self._manual_q)\n",
    "    \n",
    "    def access_children(self, move):\n",
    "        try:\n",
    "            return self._children[move]\n",
    "        except:\n",
    "            return self._children[self._corr_dict[move]]\n",
    "    \n",
    "    def children_generator(self):\n",
    "        for move in self._children:\n",
    "            yield (move, self._children[move])\n",
    "        for move in self._corr_dict:\n",
    "            yield (move, self._children[self._corr_dict[move]])\n",
    "    \n",
    "    def update_all(self, t_v):\n",
    "        node = self\n",
    "        while not node is None: \n",
    "            node._q += t_v\n",
    "            node._n_visit += 1\n",
    "            node = node._parent\n",
    "            t_v = -t_v\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_search_value(parent, node, c):\n",
    "        # return values \n",
    "        try:\n",
    "            value = for_node(c, parent._n_visit, node._n_visit, node._p, node._q)\n",
    "        except:\n",
    "            print(parent)\n",
    "            print(node)\n",
    "            raise\n",
    "        #print(value)\n",
    "        return value\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_frequency_value(node):\n",
    "        try:\n",
    "            return node._n_visit\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def select(self, c):\n",
    "        best_node = [0, 0]\n",
    "        best_node[0], best_node[1] = max(self._children.items(), key=lambda node: self.get_search_value(self, node[1], c))\n",
    "        return best_node\n",
    "        \n",
    "    def get_action_mask(self):\n",
    "        # only generate the action mask once\n",
    "        if not self._action_mask is None:\n",
    "            return self._action_mask\n",
    "        else:\n",
    "            raise ValueError(\"No action mask, request failure\")\n",
    "    \n",
    "    def get_action_frequency_map(self, temp=1):\n",
    "        global policy_dict\n",
    "        out = np.zeros(len(policy_dict))\n",
    "        # record all the n_visit of each node\n",
    "        nodes = self.children_generator()\n",
    "        for node in nodes:\n",
    "            out[policy_dict[node[0]]] = (float(node[1]._n_visit) / 100) ** (1/temp)\n",
    "        # normalize the array\n",
    "        out /= out.sum()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyValueNetwork():\n",
    "    def __init__(self, lr=None, is_load_model=False, is_cpu=True, verbose=False):\n",
    "        if is_cpu:\n",
    "            self._sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=24))\n",
    "        else:\n",
    "            config = tf.ConfigProto(log_device_placement=True)\n",
    "            config.gpu_options.allow_growth = True\n",
    "            self._sess = tf.Session(config=config)\n",
    "        K.set_session(self._sess)\n",
    "        \n",
    "        if is_cpu:\n",
    "            self._device = \"cpu\"\n",
    "        else:\n",
    "            self._device = \"gpu:0\"\n",
    "        \n",
    "        if is_load_model:\n",
    "            self._model = load_model('MCTS_POLICY_MODEL/train_pq_model.h5')\n",
    "            self._target_model = load_model('MCTS_POLICY_MODEL/target_pq_model.h5')\n",
    "            print(\"successfully loaded two models\")\n",
    "            if not lr is None:\n",
    "                self.update_learning_rate(lr)\n",
    "        else:\n",
    "            assert not lr is None\n",
    "            self._lr = lr\n",
    "            self._model = self.create_model()\n",
    "            self._target_model = self.create_model()\n",
    "            init = tf.global_variables_initializer()\n",
    "            self._sess.run(init)\n",
    "            print(\"new models generated\")\n",
    "            \n",
    "        # synchronize both models\n",
    "        self.update_target_model()\n",
    "        # print the model structure\n",
    "        if verbose:\n",
    "            print(self._model.summary())\n",
    "        \n",
    "    def update_learning_rate(self, lr):\n",
    "        try:\n",
    "            print(\"learning rate updated from {} to {}\".format(self._lr, lr))\n",
    "        except:\n",
    "            print(\"compile new learning rate {}\".format(lr))\n",
    "        self._lr = lr\n",
    "        self._model.compile(loss=['categorical_crossentropy', 'mse'], optimizer=Adam(lr=self._lr, decay=1e-6),\\\n",
    "                     loss_weights=[1, 1])\n",
    "        \n",
    "    def create_model(self):\n",
    "        assert K.backend() == 'tensorflow'\n",
    "        \n",
    "        def res_block(res_in):\n",
    "            x = Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(res_in)\n",
    "            x = BatchNormalization(axis=1)(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "            x = BatchNormalization(axis=1)(x)\n",
    "            x = add(inputs=[x, res_in])\n",
    "            x = Activation('relu')(x)\n",
    "            return x\n",
    "\n",
    "        with tf.device(self._device):\n",
    "            board_input = Input((6, 9, 9))\n",
    "            mask_input = Input((792, ))\n",
    "            x = Conv2D(64, (3, 3), padding='valid', kernel_regularizer=l2(1e-4))(board_input)\n",
    "            x = BatchNormalization(axis=1)(x)\n",
    "            x = Activation('relu')(x)\n",
    "            for i in range(1):\n",
    "                x = res_block(x)\n",
    "            y = x\n",
    "\n",
    "            x = Conv2D(2, (1, 1), kernel_regularizer=l2(1e-4))(y)\n",
    "            x = BatchNormalization(axis=1)(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = Flatten()(x)\n",
    "            x = Dense(792, activation='softplus', kernel_regularizer=l2(1e-4))(x)\n",
    "            x = multiply(inputs=[x, mask_input])     # this mask will mask any illegal move\n",
    "            action_output = Activation('softmax')(x)\n",
    "\n",
    "            x = Conv2D(1, (1, 1), kernel_regularizer=l2(1e-4))(y)\n",
    "            x = BatchNormalization(axis=1)(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = Flatten()(x)\n",
    "            x = Dense(128, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
    "            value_output = Dense(1, activation='tanh')(x)\n",
    "\n",
    "            model = Model(input=[board_input, mask_input],output=[action_output, value_output])\n",
    "\n",
    "        # compile the model\n",
    "        model.compile(loss=['categorical_crossentropy', 'mse'], optimizer=Adam(lr=self._lr, decay=1e-6),\\\n",
    "                         loss_weights=[1, 1])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        model_weights = self._model.get_weights()\n",
    "        self._target_model.set_weights(model_weights)\n",
    "\n",
    "    def predict(self, feature_map, action_mask, is_target=True):\n",
    "        if not is_target:\n",
    "            model = self._model\n",
    "        else:\n",
    "            model = self._target_model\n",
    "        \n",
    "        return self._sess.run(model.outputs, feed_dict={model.inputs[0]: feature_map.reshape(-1, 6, 9, 9), \\\n",
    "                                    model.inputs[1]: action_mask.reshape(-1, 792), K.learning_phase(): 0})\n",
    "    \n",
    "    def save(self):\n",
    "        self._model.save('MCTS_POLICY_MODEL/train_pq_model.h5')\n",
    "        self._target_model.save('MCTS_POLICY_MODEL/target_pq_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relay():\n",
    "    def __init__(self, life_span=20):\n",
    "        self._relay_dict = {}\n",
    "        self._counter = 0\n",
    "        self._life_span = life_span * 4\n",
    "        \n",
    "    def append(self, train_data):\n",
    "        train_data = list((zip(*train_data)))\n",
    "        # stack the small batch\n",
    "        for i in range(4):\n",
    "            train_data[i] = np.stack(train_data[i], axis=0)\n",
    "        # append new data\n",
    "        self._relay_dict[self._counter] = train_data\n",
    "        self._counter += 1\n",
    "        \n",
    "        # remove too old data\n",
    "        remove_index = -1\n",
    "        for index in self._relay_dict:\n",
    "            if self._counter - index > self._life_span:\n",
    "                remove_index = index\n",
    "        if remove_index != -1:\n",
    "            del self._relay_dict[remove_index]\n",
    "                \n",
    "    def get(self, n_data=None):\n",
    "        out = [[], [], [], []]\n",
    "        counter = 1  # output at least the latest element\n",
    "        out[0].append(self._relay_dict[self._counter-1][0])\n",
    "        out[1].append(self._relay_dict[self._counter-1][1])\n",
    "        out[2].append(self._relay_dict[self._counter-1][2])\n",
    "        out[3].append(self._relay_dict[self._counter-1][3])\n",
    "        for _, data in self._relay_dict.items():\n",
    "            if n_data is None:\n",
    "                sample_prob = 1\n",
    "            else:\n",
    "                sample_prob = float(n_data) / len(self._relay_dict)\n",
    "            if np.random.rand() < sample_prob: \n",
    "                counter += 1\n",
    "                out[0].append(data[0])\n",
    "                out[1].append(data[1])\n",
    "                out[2].append(data[2])\n",
    "                out[3].append(data[3])\n",
    "                \n",
    "        print(n_data, \"data expected to be grabbed\")\n",
    "        print(counter, \"data grabbed for training\")\n",
    "            \n",
    "        for i in range(4):\n",
    "            out[i] = np.concatenate(out[i], axis=0)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "    def __init__(self, c=1, dep_lim=10, lr=1e-3, life_span=10, is_load_model=False, is_cpu=True):\n",
    "        # slow_step means how many step we use to do typical mcts, after that we do fast play\n",
    "        self._c = c\n",
    "        self._dep_lim = dep_lim\n",
    "        self._game = Ataxx()\n",
    "        self._turn = -1\n",
    "        # generate model\n",
    "        self._network = PolicyValueNetwork(lr, is_load_model, is_cpu=is_cpu)\n",
    "        self._lr = lr\n",
    "        # generate root and expand initially its children\n",
    "        self._root = TreeNode(None) # this one will move in self play mode\n",
    "        self.further_init(self._root, self._game, self._turn, get_p_array=True)\n",
    "        self._root_store = self._root # this is a backup for reset\n",
    "        \n",
    "    def reset_root(self, move=None):\n",
    "        self._root = TreeNode(None) # this one will move in self play mode\n",
    "        self.further_init(self._root, self._game, self._turn, move, get_p_array=True)\n",
    "        self._root_store = self._root # this is a backup for reset\n",
    "        \n",
    "    def reset(self, left_space=45):\n",
    "        self._game.reset()\n",
    "        self._turn = -1\n",
    "        self._root = TreeNode(None)\n",
    "        \n",
    "        if left_space < 45:\n",
    "            steps = 0\n",
    "            is_terminal = False\n",
    "            result = 45\n",
    "            while not is_terminal and result > left_space:\n",
    "                if np.random.random() < 0.2: # 80 percent using greedy move\n",
    "                    best_move = choice(self._game.get_moves(self._turn))\n",
    "                    \n",
    "                else:\n",
    "                    best_move = self._game.get_greedy_move(self._turn)\n",
    "                    \n",
    "                self.make_a_move(best_move)\n",
    "                is_terminal = abs(self._game.evaluate(1, self._turn)) == 1\n",
    "                result = (np.array(self._game.data) == 0).sum()\n",
    "                steps += 1\n",
    "            if is_terminal:\n",
    "                print(\"reset failure, do reset again\")\n",
    "                self.reset(left_space)\n",
    "        self.reset_root()\n",
    "        try: # tell the _root which move led it here\n",
    "            self._root._move = best_move\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def plot_move_visit_freq(self):\n",
    "        nodes = sorted(self._root._children.items(), key=lambda node: self._root.get_frequency_value(node[1]), reverse=True)\n",
    "        # nodes = self._root.children_generator()\n",
    "        for node in nodes:\n",
    "            try:\n",
    "                print(\"{}: n_v:{:>6d} q_all:{:+06.6f} q:{:+06.6f} q_m:{:+06.6f} p:{:06.6f}\"\\\n",
    "                      .format(node[0], node[1]._n_visit, -node[1]._q / (node[1]._n_visit + 1), \\\n",
    "                              -node[1]._init_q, -node[1]._manual_q, node[1]._p))\n",
    "            except:\n",
    "                pass\n",
    "                      \n",
    "    def get_next_move(self, is_best=False, is_dirichlet=True, rollout_times=100, t_lim=np.nan):\n",
    "        global policy_list\n",
    "        # do mcts\n",
    "        self.rollout(rollout_times, t_lim)\n",
    "        \n",
    "        if is_best:\n",
    "            # return the best move\n",
    "            index = np.argmax(self._root.get_action_frequency_map())\n",
    "        elif is_dirichlet:\n",
    "            # return a choiced move\n",
    "            prob = (0.75*self._root.get_action_frequency_map(temp=1e-2) \\\n",
    "                         + 0.25*np.random.dirichlet(0.3*np.ones(792))) * self._root._action_mask\n",
    "            index = np.random.choice(range(792), p=prob / prob.sum())\n",
    "        else:\n",
    "            # return move with prob equal to visit frequency\n",
    "            index = np.random.choice(range(792), p=self._root.get_action_frequency_map())\n",
    "            \n",
    "        if index != np.argmax(self._root.get_action_frequency_map()):\n",
    "            print(\"\\n\\nThis is a random move\\n\\n\")\n",
    "            \n",
    "        return policy_list[index]\n",
    "    \n",
    "    def make_a_move(self, next_move):\n",
    "        # move the root to next_move's root\n",
    "        if self._root._children == {}:\n",
    "            self._root = TreeNode(None)\n",
    "        elif type(self._root.access_children(next_move)) is np.float32: # the root may not be neccessarily expanded\n",
    "            self._root = TreeNode(None)\n",
    "        else:\n",
    "            self._root = self._root.access_children(next_move)\n",
    "            self._root._parent = None # necessary for updata_all\n",
    "        \n",
    "        # update the game board\n",
    "        self._game.move_to(self._turn, next_move[0], next_move[1])\n",
    "        self._turn = -self._turn\n",
    "      \n",
    "    def further_init(self, node, game, turn, prev_move=None, get_p_array=False):\n",
    "        global policy_dict, policy_list\n",
    "        node._prev_move = prev_move # tell which move led the node here\n",
    "        # preparing all children\n",
    "        new_moves, node._corr_dict, node._children, node._action_mask \\\n",
    "                                = game.get_moves(turn, return_node_info=True)\n",
    "        # if meet end of the game, generate manual q\n",
    "        if node._children == {}:\n",
    "            if node._manual_q == -5:\n",
    "                node._manual_q = game.get_manual_q(turn, game.data)\n",
    "            # quite tricky here dude, remember to look from the parent perspective\n",
    "            if node._manual_q > 0:\n",
    "                node._q = 1\n",
    "            else:\n",
    "                node._q = -1 \n",
    "            return\n",
    "        \n",
    "        # generate feature map\n",
    "        node._feature_map = game.get_feature_map(turn, prev_move)\n",
    "        node._board = game.data.copy()\n",
    "        # if required, generate p array and q, only if there are children\n",
    "        if get_p_array:\n",
    "            # generate policy prob array\n",
    "            out = self._network.predict(node._feature_map, node._action_mask)\n",
    "            p_array = out[0]\n",
    "            # give p to each child (float32)\n",
    "            for move in new_moves:\n",
    "                node._children[move] = p_array[0][policy_dict[move]]\n",
    "            # init node._q\n",
    "            node._init_q = out[1][0][0] \n",
    "            node._manual_q = game.get_manual_q(turn, game.data)\n",
    "            node.get_start_q()\n",
    "        \n",
    "    def expand(self, node, game, turn):\n",
    "        global policy_dict, policy_list\n",
    "        \n",
    "        # if the node was not expanded, take that as a new root and further init it\n",
    "        if node._children == {} and node._q == 0:\n",
    "            self.further_init(node, game, turn, get_p_array=True)\n",
    "        # if end of game, quit expanding\n",
    "        if node._children == {}:\n",
    "            assert node._q != 0\n",
    "            return\n",
    "        \n",
    "        # update expanded state\n",
    "        node._is_expanded = True\n",
    "        \n",
    "        # if there are children\n",
    "        backup_board = game.data.copy() # warning, to backup a memoryview ndarray, use copy()\n",
    "        index_list = []\n",
    "        feature_map = []\n",
    "        action_mask = []\n",
    "        boards = []\n",
    "        for move in node._children:\n",
    "            tmp = node._children[move]\n",
    "            try:\n",
    "                assert type(tmp) is np.float32\n",
    "            except:\n",
    "                print(type(tmp))\n",
    "                raise\n",
    "            new_node = TreeNode(node, p=node._children[move])\n",
    "            game.move_to(turn,  move[0], move[1])\n",
    "            self.further_init(new_node, game, -turn, move, get_p_array=False)\n",
    "            node._children[move] = new_node\n",
    "            # prepare to calculate p for new_node only if it has children\n",
    "            if new_node._children != {}:\n",
    "                index_list.append(new_node)\n",
    "                feature_map.append(new_node._feature_map)\n",
    "                action_mask.append(new_node._action_mask)\n",
    "                boards.append(new_node._board)\n",
    "            # reset the gamer\n",
    "            game.reset(board=backup_board)\n",
    "        # if there are no more node that is expandable, quit\n",
    "        if len(index_list) == 0:\n",
    "            return\n",
    "        \n",
    "        # do batch prediction\n",
    "        # print(\"batch size:\", len(index_list))\n",
    "        feature_map = np.stack(feature_map, axis=0)\n",
    "        action_mask = np.stack(action_mask, axis=0)\n",
    "        out = self._network.predict(feature_map, action_mask)\n",
    "        # get batch manual q \n",
    "        boards = [game.get_manual_q(-turn, board) for board in boards]\n",
    "        # update the result to each child node\n",
    "        for i, child in enumerate(index_list):\n",
    "            # assign q\n",
    "            child._manual_q = boards[i] # neg for display use\n",
    "            child._init_q = out[1][i][0] # same as above\n",
    "            child.get_start_q()\n",
    "            # assign p\n",
    "            assign_children(child._children, out[0][i])\n",
    "            \n",
    "\n",
    "    def rollout(self, rollout_times=100, t_lim=np.nan, t_min=2):\n",
    "        start = time.time()\n",
    "        for i in range(rollout_times*5):\n",
    "            tmp_node = self._root\n",
    "            tmp_game = Ataxx(self._game.data)\n",
    "            tmp_turn = self._turn\n",
    "            # start mcts\n",
    "            step = 0\n",
    "            while True:\n",
    "                assert self._dep_lim > 0\n",
    "                if step < self._dep_lim:\n",
    "                    # expand the node only when it has never been expanded\n",
    "                    if tmp_node._is_expanded == False:\n",
    "                        self.expand(tmp_node, tmp_game, tmp_turn)\n",
    "\n",
    "                    # check if is leaf node, if so, update the whole tree\n",
    "                    if tmp_node._children == {}:\n",
    "                        t_v = tmp_node._q / (tmp_node._n_visit + 1)\n",
    "                        tmp_node.update_all(t_v)\n",
    "                        break\n",
    "                    else:\n",
    "                        # select a child and continue exploration\n",
    "                        next_move, next_node = tmp_node.select(self._c)\n",
    "                            \n",
    "                        # move to next move and next node\n",
    "                        tmp_game.move_to(tmp_turn, next_move[0], next_move[1])    \n",
    "                        tmp_node = next_node\n",
    "                        tmp_turn = -tmp_turn\n",
    "                else:\n",
    "                    t_v = tmp_node._q / (tmp_node._n_visit + 1)\n",
    "                    tmp_node.update_all(t_v)\n",
    "                    break\n",
    "                # update steps                                    \n",
    "                step += 1\n",
    "            cur_time = time.time() - start\n",
    "            if cur_time > t_lim * 0.999:\n",
    "                print(\"due to time lim, final rollout times: \", i, \"time elapsed: \", cur_time)\n",
    "                break\n",
    "            \n",
    "            if cur_time > t_min and i > rollout_times:\n",
    "                print(\"due to rollout lim, final rollout times: \", i, \"time elapsed: \", cur_time)\n",
    "                break\n",
    "                \n",
    "        \n",
    "    def testing_against_greedy(self, rounds=5, left_space=45, c=5, dep_lim=0, rollout_times=400, t_lim=6, verbose=True):\n",
    "        print(\"####               ####\")\n",
    "        print(\"#### start testing ####\")\n",
    "        # record dep_lim and c for restoration\n",
    "        store_dep_lim = self._dep_lim\n",
    "        self._dep_lim = dep_lim\n",
    "        store_c = self._c\n",
    "        self._c = c\n",
    "        # recorder of game result\n",
    "        n_win = 0.0\n",
    "        win_steps = 0.0\n",
    "        for r in range(rounds):\n",
    "            tmp_round_s = time.time()\n",
    "            # randomly init the game board if no left_space specified\n",
    "            self.reset(left_space)\n",
    "            # set up start turns\n",
    "            my_turn = choice([-1, 1])\n",
    "            if verbose:\n",
    "                print(\"round:\", r+1)\n",
    "                print(\"this game start with {} space left\".format(left_space))\n",
    "                print(\"self takes turn: \", my_turn)\n",
    "            # start the game\n",
    "            steps = 0\n",
    "            while abs(self._game.evaluate(1, self._turn)) != 1:\n",
    "                # plot the game board\n",
    "                if verbose:\n",
    "                    self._game.plot()\n",
    "                    tmp_s = time.time()\n",
    "                if self._turn == my_turn:\n",
    "                    best_move = self.get_next_move(is_best=True, rollout_times=rollout_times, t_lim=t_lim)\n",
    "                    if verbose:\n",
    "                        print(\"self turn\", my_turn)\n",
    "                        print(self.plot_move_visit_freq())\n",
    "                else:\n",
    "                    best_move = self._game.get_greedy_move(self._turn)\n",
    "                    if verbose:\n",
    "                        print(\"greedy turn\", self._turn)\n",
    "                if verbose:\n",
    "                    print(\"this move takes time(s): \", time.time()-tmp_s)\n",
    "                    print(\"chosen move is \", best_move)\n",
    "\n",
    "                # synchronize steps and boards\n",
    "                self.make_a_move(best_move)\n",
    "                # update steps\n",
    "                steps += 1\n",
    "                if steps > 250:\n",
    "                    print(\"steps over 250, game skip\")\n",
    "                    break\n",
    "            if steps <= 250:\n",
    "                is_self_win = self._game.evaluate(my_turn, self._turn) == 1\n",
    "                if is_self_win:\n",
    "                    n_win += 1\n",
    "                    win_steps += steps\n",
    "                if verbose:\n",
    "                    print(\"this round has steps: {}, time taken: {}, \\n\\n\\nself wins? {}\\n\\n\\n\".format(steps, time.time()-tmp_round_s, is_self_win))\n",
    "            else:\n",
    "                n_win += 0.5\n",
    "        # restore dep lim and c\n",
    "        self._dep_lim = store_dep_lim\n",
    "        self._c = store_c\n",
    "        \n",
    "        # output\n",
    "        if n_win == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            print(win_steps / n_win)\n",
    "        return n_win / rounds\n",
    "    \n",
    "    def tester(self):\n",
    "        q_ratio = self.testing_against_greedy(\\\n",
    "            rounds=50, left_space=45, c=0, dep_lim=1, rollout_times=1, t_lim=6, verbose=False)\n",
    "        print(\"\\n\\n\\n                        win ratio of Q is {} \\n\\n\\n\\n\\n\".format(q_ratio))\n",
    "        p_ratio = self.testing_against_greedy(\\\n",
    "            rounds=50, left_space=45, c=100, dep_lim=1, rollout_times=1, t_lim=6, verbose=False)\n",
    "        print(\"\\n\\n\\n                        win ratio of P is {} \\n\\n\\n\\n\\n\".format(p_ratio))\n",
    "        both_ratio = self.testing_against_greedy(\\\n",
    "            rounds=50, left_space=45, c=5, dep_lim=1, rollout_times=500, t_lim=6, verbose=False)\n",
    "        print(\"\\n\\n\\n                        win ratio of both is {} \\n\\n\\n\\n\\n\".format(both_ratio))\n",
    "             \n",
    "    def data_collector(self, node, visit_min):\n",
    "        out = []\n",
    "        if node._n_visit >= visit_min:\n",
    "            tmp_data = [node._feature_map, \\\n",
    "                        node._action_mask, \\\n",
    "                        node.get_action_frequency_map(),\\\n",
    "                        recover_q(node._q / (node._n_visit + 1), node._manual_q)] # to recover what policy q should be\n",
    "            tmp_data = augment_data(tmp_data)\n",
    "            out.extend(tmp_data)\n",
    "\n",
    "        for _, child in node._children.items():\n",
    "            if child._n_visit == node._n_visit: # skip node itself\n",
    "                continue\n",
    "            try: \n",
    "                assert child._n_visit >= visit_min * 1.25\n",
    "                tmp_data = [child._feature_map, \\\n",
    "                            child._action_mask, \\\n",
    "                            child.get_action_frequency_map(),\\\n",
    "                            recover_q(child._q / (child._n_visit + 1), child._manual_q)]\n",
    "                tmp_data = augment_data(tmp_data)\n",
    "                out.extend(tmp_data)\n",
    "            except:\n",
    "                pass\n",
    "        print(\"no. of data collected: \", len(out))\n",
    "        return out\n",
    "        \n",
    "                \n",
    "    def self_play(self, rollout_times=100, t_lim=np.nan, verbose=True, is_best=False):\n",
    "        train_data = []\n",
    "        steps = 0\n",
    "        print(\"start new self play\")\n",
    "        start = time.time()\n",
    "        while self._root._children != {} and steps < 250:\n",
    "            print(self._turn, \"'s turn\")\n",
    "            tmp_s = time.time()\n",
    "            if steps < 5: # to generate different game data\n",
    "                best_move = self.get_next_move(is_best=is_best, is_dirichlet=False, \\\n",
    "                                               rollout_times=rollout_times, t_lim=t_lim)\n",
    "            else:\n",
    "                best_move = self.get_next_move(is_best=is_best, is_dirichlet=True, \\\n",
    "                                               rollout_times=rollout_times, t_lim=t_lim)\n",
    "            print(\"one move takes time(s): \", time.time()-tmp_s)\n",
    "            # record π data\n",
    "            visit_min = rollout_times\n",
    "            train_data.extend(self.data_collector(self._root, visit_min))\n",
    "            # plot the game board if verbose\n",
    "            if verbose:\n",
    "                self._game.plot()\n",
    "                self.plot_move_visit_freq()\n",
    "            # make the move and move on\n",
    "            self.make_a_move(best_move)\n",
    "            steps += 1\n",
    "        print(\"this self play has {} steps, time elapsed {}\".format(steps, time.time()-start))\n",
    "        print(\"winner is\", np.sign(self._root._q * self._turn))\n",
    "        \n",
    "        return train_data\n",
    "            \n",
    "    def reinforcement_learning(self, episode=1000, rollout_times=100, life_span=25, t_lim=np.nan, left_space_max=None, self_play_verbose=False):        \n",
    "        train_relay = Relay(life_span)\n",
    "        for epi in range(episode):\n",
    "            print(\"episode {} now start\".format(epi))\n",
    "            self.reset_root()\n",
    "            # randomly skip a few steps if left space not specified\n",
    "            if not left_space_max is None:\n",
    "                left_space = left_space_max * np.random.normal(loc=1, scale=0.2)\n",
    "            else:\n",
    "                left_space = 45\n",
    "            self.reset(left_space=left_space)\n",
    "            print(\"left space is {}\".format(left_space))\n",
    "            # start self_play and get train_data\n",
    "            if np.random.random() < 0.05:\n",
    "                train_data = self.self_play(rollout_times=rollout_times, t_lim=t_lim, verbose=True)\n",
    "            else:\n",
    "                train_data = self.self_play(rollout_times=rollout_times, t_lim=t_lim, verbose=self_play_verbose)\n",
    "            # store it in relay\n",
    "            train_relay.append(train_data)\n",
    "            # do training every 5 epi and update target model and reset tree\n",
    "            if epi % (life_span) == 0:\n",
    "                print(\"\\n\\nstart testing against greedy\")\n",
    "                self.tester()\n",
    "                self._lr = self._lr / 1.5\n",
    "                self._network.update_learning_rate(self._lr)\n",
    "            if epi >= life_span and epi%int(life_span/6) == 0:\n",
    "                train_data = train_relay.get(life_span)\n",
    "                print(\"start training, training data no. {}\".format(train_data[0].shape[0]))\n",
    "                # do training\n",
    "                es = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=128, verbose=1, mode='auto')\n",
    "                self._network._model.fit(x=[train_data[0], train_data[1]], y=[train_data[2], train_data[3]], verbose=1, \\\n",
    "                                            batch_size=512, epochs=256, shuffle=True, validation_split=0.1, callbacks=[es])\n",
    "                self._network.update_target_model()\n",
    "                print(\"saving files\")\n",
    "                self._network.save()\n",
    "            print(\"episode {} finished\".format(epi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded two models\n",
      "compile new learning rate 2e-06\n"
     ]
    }
   ],
   "source": [
    "player = MCTS(is_cpu=False, lr=2e-6, c=5, is_load_model=True, dep_lim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0 now start\n",
      "left space is 45\n",
      "start new self play\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.32024645805358887\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.31201982498168945\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.4398629665374756\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.5105302333831787\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.6086745262145996\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.7051591873168945\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  0.7609724998474121\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.1332647800445557\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  0.6924874782562256\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.7910845279693604\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.5791709423065186\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.0931987762451172\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.6629393100738525\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.4956040382385254\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9988853931427002\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.1537322998046875\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1263175010681152\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.0748279094696045\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.8547348976135254\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "one move takes time(s):  1.026397943496704\n",
      "no. of data collected:  32\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2941100597381592\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.194969654083252\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.3178644180297852\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.8307266235351562\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1307246685028076\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.0028417110443115\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.0204439163208008\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.7986516952514648\n",
      "no. of data collected:  40\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9422974586486816\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.3265125751495361\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.6794977188110352\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.2409307956695557\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.593156099319458\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.479184627532959\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.3498945236206055\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.9378924369812012\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "due to rollout lim, final rollout times:  4029 time elapsed:  2.000091791152954\n",
      "one move takes time(s):  2.001790761947632\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.0146167278289795\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.248856544494629\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.7268362045288086\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.8892014026641846\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.169769048690796\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.8182404041290283\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.8532335758209229\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.7465918064117432\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.5979976654052734\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.5964205265045166\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.7481653690338135\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.5103697776794434\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.6389844417572021\n",
      "no. of data collected:  32\n",
      "-1 's turn\n",
      "one move takes time(s):  0.6152458190917969\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.4507901668548584\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.40052008628845215\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.5816323757171631\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.5519566535949707\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.49840259552001953\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.44373440742492676\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.39828014373779297\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.4272632598876953\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.3358745574951172\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.28337740898132324\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.28060102462768555\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.21068167686462402\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.2694432735443115\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.2008826732635498\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "one move takes time(s):  0.21359038352966309\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.11531901359558105\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.10208487510681152\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.08455419540405273\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.08352351188659668\n",
      "no. of data collected:  8\n",
      "this self play has 70 steps, time elapsed 59.69833064079285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuze/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:111: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner is 1.0\n",
      "\n",
      "\n",
      "start testing against greedy\n",
      "####               ####\n",
      "#### start testing ####\n",
      "due to rollout lim, final rollout times:  2 time elapsed:  2.63100004196167\n",
      "68.28571428571429\n",
      "\n",
      "\n",
      "\n",
      "                        win ratio of Q is 0.42 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####               ####\n",
      "#### start testing ####\n",
      "62.09090909090909\n",
      "\n",
      "\n",
      "\n",
      "                        win ratio of P is 0.22 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####               ####\n",
      "#### start testing ####\n",
      "60.592592592592595\n",
      "\n",
      "\n",
      "\n",
      "                        win ratio of both is 0.54 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "learning rate updated from 2e-06 to 1.3333333333333332e-06\n",
      "episode 0 finished\n",
      "episode 1 now start\n",
      "left space is 45\n",
      "start new self play\n",
      "-1 's turn\n",
      "one move takes time(s):  0.2917656898498535\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.3255918025970459\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.4407012462615967\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.504528284072876\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.6280820369720459\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  0.6953761577606201\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  0.6761431694030762\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.6958439350128174\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.6293888092041016\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.7401974201202393\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.7801027297973633\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.1791090965270996\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.8991563320159912\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  1.2445135116577148\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.7167081832885742\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "one move takes time(s):  1.0927751064300537\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.6912508010864258\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.3813345432281494\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9291963577270508\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.6217269897460938\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.07590913772583\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.5689258575439453\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.0484848022460938\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.6252779960632324\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.0692863464355469\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.65995454788208\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.383169412612915\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "due to rollout lim, final rollout times:  4414 time elapsed:  2.0000579357147217\n",
      "one move takes time(s):  2.0018310546875\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1047053337097168\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "due to rollout lim, final rollout times:  2644 time elapsed:  2.0000903606414795\n",
      "one move takes time(s):  2.0013599395751953\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "due to rollout lim, final rollout times:  1001 time elapsed:  3.13655948638916\n",
      "one move takes time(s):  3.137572765350342\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "due to rollout lim, final rollout times:  3478 time elapsed:  2.003514528274536\n",
      "one move takes time(s):  2.004939079284668\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.8248703479766846\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "due to rollout lim, final rollout times:  2455 time elapsed:  2.0001189708709717\n",
      "one move takes time(s):  2.00154972076416\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.661447525024414\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "due to rollout lim, final rollout times:  4241 time elapsed:  2.019068479537964\n",
      "one move takes time(s):  2.020325183868408\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.4347951412200928\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.7809274196624756\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.4160332679748535\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "due to rollout lim, final rollout times:  2401 time elapsed:  2.0000381469726562\n",
      "one move takes time(s):  2.001678466796875\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2853410243988037\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.5593149662017822\n",
      "no. of data collected:  32\n",
      "-1 's turn\n",
      "one move takes time(s):  1.4213199615478516\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "due to rollout lim, final rollout times:  2705 time elapsed:  2.0001440048217773\n",
      "one move takes time(s):  2.001587152481079\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.83298659324646\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "due to rollout lim, final rollout times:  2356 time elapsed:  2.0000998973846436\n",
      "one move takes time(s):  2.0014050006866455\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.8553283214569092\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.7660090923309326\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.7225275039672852\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "due to rollout lim, final rollout times:  3087 time elapsed:  2.000032663345337\n",
      "one move takes time(s):  2.001432180404663\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2672014236450195\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.2867391109466553\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "due to rollout lim, final rollout times:  1001 time elapsed:  4.169873952865601\n",
      "one move takes time(s):  4.171283960342407\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  1.6347978115081787\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2577531337738037\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.427687406539917\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9146599769592285\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.157144546508789\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.8868827819824219\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.8897702693939209\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.5131130218505859\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.7921550273895264\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.7232978343963623\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.7602407932281494\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.5996854305267334\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "one move takes time(s):  0.37308335304260254\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.4379105567932129\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.5562894344329834\n",
      "no. of data collected:  32\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.42177844047546387\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.45470643043518066\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.27198076248168945\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.2652149200439453\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.23055505752563477\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.17267179489135742\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.15608477592468262\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.197096586227417\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.11522936820983887\n",
      "no. of data collected:  16\n",
      "1 's turn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one move takes time(s):  0.11141729354858398\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.08041238784790039\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.0824747085571289\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.07586956024169922\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.06882977485656738\n",
      "no. of data collected:  8\n",
      "this self play has 82 steps, time elapsed 91.88503050804138\n",
      "winner is 1.0\n",
      "episode 1 finished\n",
      "episode 2 now start\n",
      "left space is 45\n",
      "start new self play\n",
      "-1 's turn\n",
      "one move takes time(s):  0.2691364288330078\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.33116650581359863\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.43016505241394043\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.47823596000671387\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.6029953956604004\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  0.6088263988494873\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.7338812351226807\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  0.7767622470855713\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.8835375308990479\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  0.9682276248931885\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1395933628082275\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  1.170320987701416\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.176743507385254\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.8028159141540527\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2667510509490967\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.3729751110076904\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.0785021781921387\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.3066730499267578\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1729857921600342\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.5105030536651611\n",
      "no. of data collected:  32\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2737183570861816\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.567096471786499\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.6885437965393066\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.2389392852783203\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.7280020713806152\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.4704647064208984\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9470016956329346\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.0527429580688477\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1594386100769043\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "due to time lim, final rollout times:  1326 time elapsed:  8.056788921356201\n",
      "one move takes time(s):  8.074220418930054\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9208519458770752\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.9613628387451172\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.210824728012085\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.8943400382995605\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.3552744388580322\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.2096564769744873\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1718199253082275\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.9627392292022705\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.4037177562713623\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "one move takes time(s):  1.2985060214996338\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.2893571853637695\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.0986077785491943\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2709705829620361\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.8513374328613281\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1526598930358887\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "one move takes time(s):  0.8156447410583496\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.8840923309326172\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.8756365776062012\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9523730278015137\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.5915844440460205\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.5224857330322266\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.560593843460083\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.0019259452819824\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.5578429698944092\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.741112232208252\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.4781177043914795\n",
      "no. of data collected:  32\n",
      "-1 's turn\n",
      "one move takes time(s):  0.4646930694580078\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.3647150993347168\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.33498644828796387\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.3111395835876465\n",
      "no. of data collected:  32\n",
      "-1 's turn\n",
      "one move takes time(s):  0.4361698627471924\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.2811582088470459\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.35924243927001953\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.20503497123718262\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.23973536491394043\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.20906376838684082\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.23322486877441406\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.15662002563476562\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.16278362274169922\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "one move takes time(s):  0.1442708969116211\n",
      "no. of data collected:  32\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.11576366424560547\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.10315799713134766\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.07065796852111816\n",
      "no. of data collected:  8\n",
      "this self play has 73 steps, time elapsed 69.60349178314209\n",
      "winner is -1.0\n",
      "episode 2 finished\n",
      "episode 3 now start\n",
      "left space is 45\n",
      "start new self play\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.2762913703918457\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.3564605712890625\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.4379868507385254\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.5231454372406006\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.6775562763214111\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.7048773765563965\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.8977861404418945\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.8896138668060303\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1314969062805176\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  1.068340539932251\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2806916236877441\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  1.1529152393341064\n",
      "no. of data collected:  16\n",
      "-1 's turn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.1239030361175537\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "one move takes time(s):  1.3879458904266357\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.1030972003936768\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.5780162811279297\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.3929507732391357\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.5038907527923584\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.480579137802124\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.1172163486480713\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2055907249450684\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.9800176620483398\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "due to rollout lim, final rollout times:  1001 time elapsed:  6.117862701416016\n",
      "one move takes time(s):  6.1191487312316895\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.5123255252838135\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.4956519603729248\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.2629456520080566\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.2089614868164062\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.5249018669128418\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.486419677734375\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.3625218868255615\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.3170490264892578\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.188645362854004\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.125800609588623\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.3085529804229736\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.09326171875\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "one move takes time(s):  1.0956006050109863\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9747085571289062\n",
      "no. of data collected:  32\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  1.213505506515503\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2213373184204102\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.9514915943145752\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.034825086593628\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.9139742851257324\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9167494773864746\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.7665486335754395\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.6835143566131592\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.6418216228485107\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.5602786540985107\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.5364768505096436\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.705338716506958\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.455935001373291\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.5440447330474854\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.44452714920043945\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.2840614318847656\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.32564663887023926\n",
      "no. of data collected:  32\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.4451613426208496\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.31157970428466797\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.2833237648010254\n",
      "no. of data collected:  40\n",
      "1 's turn\n",
      "one move takes time(s):  0.2274007797241211\n",
      "no. of data collected:  24\n",
      "-1 's turn\n",
      "one move takes time(s):  0.2512080669403076\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  0.15658092498779297\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.19334983825683594\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  0.09456586837768555\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.11124134063720703\n",
      "no. of data collected:  8\n",
      "this self play has 63 steps, time elapsed 62.34646463394165\n",
      "winner is -1.0\n",
      "episode 3 finished\n",
      "episode 4 now start\n",
      "left space is 45\n",
      "start new self play\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.2802135944366455\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.31975531578063965\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.3983879089355469\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.473675012588501\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.6026663780212402\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  0.6595075130462646\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "\n",
      "\n",
      "This is a random move\n",
      "\n",
      "\n",
      "one move takes time(s):  0.778996467590332\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  0.8499469757080078\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.0280852317810059\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  1.1951189041137695\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.2774848937988281\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.199016809463501\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  0.9750056266784668\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.3023438453674316\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.388439655303955\n",
      "no. of data collected:  24\n",
      "1 's turn\n",
      "one move takes time(s):  1.132352352142334\n",
      "no. of data collected:  16\n",
      "-1 's turn\n",
      "one move takes time(s):  1.4231507778167725\n",
      "no. of data collected:  8\n",
      "1 's turn\n",
      "one move takes time(s):  1.6393048763275146\n",
      "no. of data collected:  8\n",
      "-1 's turn\n",
      "one move takes time(s):  1.387967586517334\n",
      "no. of data collected:  16\n",
      "1 's turn\n",
      "one move takes time(s):  1.413783311843872\n",
      "no. of data collected:  16\n",
      "-1 's turn\n"
     ]
    }
   ],
   "source": [
    "player.reinforcement_learning(episode=300, left_space_max=None, rollout_times=1000, life_span=25, t_lim=8, self_play_verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset successful\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e5c5a3940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "due to rollout lim, final rollout times:  1601 time elapsed:  3.9874846935272217\n",
      "((4, 1), (4, 0)): n_v:  1052 q_all:+0.013513 q:+0.049070 q_m:-0.200000 p:0.002485\n",
      "((4, 2), (2, 4)): n_v:   239 q_all:+0.011836 q:+0.073340 q_m:-0.140000 p:0.002548\n",
      "((6, 0), (4, 0)): n_v:   233 q_all:+0.011676 q:+0.026379 q_m:-0.228000 p:0.002703\n",
      "((4, 3), (2, 4)): n_v:    13 q_all:-0.022183 q:+0.059676 q_m:-0.140000 p:0.002351\n",
      "((4, 2), (2, 0)): n_v:    11 q_all:-0.027423 q:+0.021419 q_m:-0.180000 p:0.002421\n",
      "((0, 0), (1, 2)): n_v:    11 q_all:-0.027220 q:+0.035929 q_m:-0.180000 p:0.002356\n",
      "((4, 3), (6, 5)): n_v:     9 q_all:-0.037983 q:+0.083477 q_m:-0.228000 p:0.002581\n",
      "((4, 1), (2, 0)): n_v:     8 q_all:-0.044054 q:+0.053543 q_m:-0.180000 p:0.002409\n",
      "((0, 0), (2, 0)): n_v:     8 q_all:-0.041931 q:+0.020312 q_m:-0.180000 p:0.002386\n",
      "((0, 0), (1, 0)): n_v:     6 q_all:-0.064221 q:+0.041322 q_m:-0.256000 p:0.002550\n",
      "((4, 2), (4, 0)): n_v:     4 q_all:-0.087413 q:+0.021795 q_m:-0.228000 p:0.002377\n",
      "((0, 0), (0, 1)): n_v:     4 q_all:-0.099626 q:+0.030006 q_m:-0.312000 p:0.002531\n",
      "((0, 0), (0, 2)): n_v:     4 q_all:-0.085551 q:+0.029099 q_m:-0.340000 p:0.002424\n"
     ]
    }
   ],
   "source": [
    "#player = MCTS(is_cpu=True, c=4, is_load_model=False, dep_lim=5)\n",
    "player._dep_lim = 3\n",
    "player._c = 5\n",
    "player.reset(20)\n",
    "player._game.plot()\n",
    "print(player._turn)\n",
    "%lprun -f player.expand player.rollout(1600, np.nan)\n",
    "#%time player.rollout(1000, np.nan)\n",
    "player.plot_move_visit_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = player._network._model.get_weights()\n",
    "fig = plt.gcf()\n",
    "print(w[0].shape)\n",
    "show_w = w[0]\n",
    "for in_layer in range(6):\n",
    "    for out_layer in range(64):\n",
    "        print('in', in_layer, 'out', out_layer)\n",
    "        plt.imshow(show_w[..., in_layer, out_layer], cmap='gray')\n",
    "        plt.pause(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
