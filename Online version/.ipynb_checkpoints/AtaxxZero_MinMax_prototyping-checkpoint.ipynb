{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T17:38:52.214227Z",
     "start_time": "2018-03-01T17:38:52.202969Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "import line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T17:38:55.522707Z",
     "start_time": "2018-03-01T17:38:52.592053Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import importlib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from math import sqrt, log, exp\n",
    "from numpy import unravel_index\n",
    "from random import choice, random, sample\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import Sequential, Model, load_model\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "K.set_image_dim_ordering('th')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T17:46:24.743244Z",
     "start_time": "2018-03-01T17:46:22.293321Z"
    }
   },
   "outputs": [],
   "source": [
    "class Ataxx:\n",
    "    def __init__(self, board=None):\n",
    "        if board is None:                  # if there is no initialization given\n",
    "            self.data = np.zeros((7, 7), dtype=np.int8)   # then generate a board with starting init, and black(-1) takes first turn\n",
    "            self.data[0, 0] = -1           \n",
    "            self.data[6, 6] = -1\n",
    "            self.data[0, 6] = 1\n",
    "            self.data[6, 0] = 1\n",
    "        else:\n",
    "            self.data = board.copy()\n",
    "            \n",
    "    def reset(self, board=None):\n",
    "        if board is None:\n",
    "            self.data = np.zeros((7, 7), dtype=np.int8)\n",
    "            self.data[0, 0] = -1           \n",
    "            self.data[6, 6] = -1\n",
    "            self.data[0, 6] = 1\n",
    "            self.data[6, 0] = 1\n",
    "        else:\n",
    "            self.data = board.copy()\n",
    "        \n",
    "    def get_feature_map(self, turn, move):\n",
    "        out = np.zeros((6, 9, 9), dtype=np.int8)\n",
    "        # define 1 edge\n",
    "        \n",
    "        # edge\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if j == 0 or j == 8 or k == 0 or k == 8:\n",
    "                    out[0, j, k] = 1\n",
    "         \n",
    "        # my pieces\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if j > 0 and j < 8 and k > 0 and k < 8:\n",
    "                    if self.data[j-1, k-1] == turn:\n",
    "                        out[1, j, k] = 1\n",
    "        \n",
    "        # op pieces\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if j > 0 and j < 8 and k > 0 and k < 8:\n",
    "                    if self.data[j-1, k-1] == -turn:\n",
    "                        out[2, j, k] = 1\n",
    "         \n",
    "        # last move\n",
    "        if not move is None:               \n",
    "            out[3, move[0][0]+1, move[0][1]+1] = 1\n",
    "            out[4, move[1][0]+1, move[1][1]+1] = 1\n",
    "            \n",
    "        # whose first\n",
    "        if turn == -1:\n",
    "            for j in range(9):\n",
    "                for k in range(9):\n",
    "                    out[5, j, k] = 1\n",
    "        return np.array(out)\n",
    "    \n",
    "    def plot(self, is_next_move=False, turn=None):                        # plot the board\n",
    "        image = self.data.copy()\n",
    "        if is_next_move:\n",
    "            if turn not in [-1, 1]:\n",
    "                raise ValueError(\"Turn must be -1 or 1, or Must input a turn for next moves\")\n",
    "            else:\n",
    "                next_moves = self.get_moves(turn)\n",
    "                if len(next_moves) == 0:\n",
    "                    raise ValueError(\"Game is over already\")\n",
    "                next_pos = list(zip(*next_moves))[1]\n",
    "                for pos in next_pos:\n",
    "                    image[pos] = turn / 2\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.xticks(range(7), range(7))\n",
    "        plt.yticks(range(7), range(7))\n",
    "        plt.show()\n",
    "        \n",
    "    def get_greedy_move(self, turn, moves=None):\n",
    "        best_score = -50\n",
    "        # get all possible moves if not provided\n",
    "        if moves is None:\n",
    "            moves, corr_dict = self.get_moves(turn)\n",
    "            for item in corr_dict:\n",
    "                moves.append(item)\n",
    "        \n",
    "        if len(moves) == 0:\n",
    "            raise ValueError('No Possible Moves')\n",
    "        \n",
    "        best_moves = []\n",
    "        # calculate greedy move\n",
    "        for (x0, y0), (x1, y1) in moves:\n",
    "            tmp_score = 0\n",
    "            if abs(x0-x1) <= 1 and abs(y0-y1) <= 1:\n",
    "                tmp_score += 1\n",
    "            for dr in range(-1, 2):\n",
    "                for dc in range(-1, 2):\n",
    "                    try:\n",
    "                        if x1+dr >= 0 and y1+dc >= 0:\n",
    "                            tmp_score += self.data[x1+dr, y1+dc] == -turn\n",
    "                    except:\n",
    "                        pass\n",
    "            if tmp_score > best_score:\n",
    "                best_moves = [((x0, y0), (x1, y1))]\n",
    "                best_score = tmp_score\n",
    "            elif tmp_score == best_score:\n",
    "                best_moves.append(((x0, y0), (x1, y1)))\n",
    "        return choice(best_moves)\n",
    "                \n",
    "    def is_valid(self, turn, pos, get_pos=False):\n",
    "        r = pos[0]\n",
    "        c = pos[1]\n",
    "        if self.data[r, c] != 0:\n",
    "            if not get_pos:\n",
    "                return False\n",
    "            else:\n",
    "                return\n",
    "        else:\n",
    "            for dr in range(-2, 3):\n",
    "                for dc in range(-2, 3):\n",
    "                    new_r = r+dr\n",
    "                    new_c = c+dc\n",
    "                    if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and self.data[new_r, new_c] == turn:\n",
    "                        if not get_pos:\n",
    "                            return True\n",
    "                        else:\n",
    "                            yield new_r, new_c, dr, dc\n",
    "            if not get_pos:\n",
    "                return False\n",
    "        \n",
    "    def get_moves(self, turn):\n",
    "        action_mask = np.zeros(792, dtype=np.int8)\n",
    "        next_moves = []\n",
    "        corr_dict = {}\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                has_duplicate_move = False      # move within the radius of one of another friendly piece is called\n",
    "                for new_r, new_c, dr, dc in self.is_valid(turn, (r, c), True): # duplicate move\n",
    "                    if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and self.data[new_r, new_c] == turn:\n",
    "                        if abs(dr) <= 1 and abs(dc) <=1:\n",
    "                            if has_duplicate_move: \n",
    "                                cur_move = ((new_r, new_c), (r, c))\n",
    "                                corr_dict[cur_move] = dup_move\n",
    "                            elif self.data[new_r, new_c] == turn:\n",
    "                                dup_move = ((new_r, new_c), (r, c))\n",
    "                                next_moves.append(dup_move) \n",
    "                                has_duplicate_move = True\n",
    "                        elif self.data[new_r, new_c] == turn:\n",
    "                            cur_move = ((new_r, new_c), (r, c))\n",
    "                            next_moves.append(cur_move) \n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "        return next_moves, corr_dict\n",
    "        \n",
    "    def move_to(self, turn, pos0, pos1):\n",
    "        x0 = pos0[0]\n",
    "        y0 = pos0[1]\n",
    "        x1 = pos1[0]\n",
    "        y1 = pos1[1]\n",
    "        \n",
    "        if not self.is_valid(turn, pos1):\n",
    "            raise ValueError(\"This move: \" + str((pos0, pos1)) + \" of turn: \" + str(turn) + \" is invalid\") \n",
    "        elif self.data[x0, y0] != turn:\n",
    "            raise ValueError(\"The starting position is not your piece\")\n",
    "        else:\n",
    "            self.data[x1, y1] = turn\n",
    "            if abs(x0 - x1) > 1 or abs(y0 - y1) > 1:   # jump move\n",
    "                self.data[x0, y0] = 0\n",
    "\n",
    "            for dr in range(-1, 2):                  # infection mode!!!!\n",
    "                for dc in range(-1, 2):\n",
    "                    if x1+dr >= 0 and y1+dc >= 0 and x1+dr < 7 and y1+dc < 7:\n",
    "                        if self.data[x1+dr, y1+dc] == -turn:  # convert any piece of the opponent to 'turn'\n",
    "                            self.data[x1+dr, y1+dc] = turn\n",
    "    \n",
    "    def evaluate(self, turn, this_turn, max_score=1, min_score=0.001):\n",
    "        turn_no=0\n",
    "        op_no=0\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                if self.data[r, c] == turn:\n",
    "                    turn_no += 1\n",
    "                elif self.data[r, c] == -turn:\n",
    "                    op_no += 1\n",
    "        if len(self.get_moves(this_turn)[0]) == 0:# if one of them can no longer move, count and end\n",
    "            if turn_no > op_no:\n",
    "                return max_score\n",
    "            else:\n",
    "                return -max_score\n",
    "        else:\n",
    "            value = turn_no - op_no\n",
    "        return value * min_score\n",
    "    \n",
    "    @staticmethod    \n",
    "    def get_manual_q(turn, board):\n",
    "        '''consider linear growth of win prob with regard to n_diff\n",
    "        when diff >= 10, the slope grow a bit\n",
    "        when diff >= 35, consider win prob close to 1 or -1\n",
    "        ''' \n",
    "        turn_no = 0\n",
    "        op_no = 0\n",
    "        max1=0.9\n",
    "        max2=0.95\n",
    "        # get no diff of turns\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                if board[r, c] == turn:\n",
    "                    turn_no += 1\n",
    "                elif board[r, c] == -turn:\n",
    "                    op_no += 1\n",
    "        diff = turn_no - op_no\n",
    "        if abs(diff) > 30:\n",
    "            return diff / abs(diff)\n",
    "        else:\n",
    "            return diff / 30\n",
    "        \n",
    "        # ignore the rest for now\n",
    "        sign = diff\n",
    "        diff = abs(diff)\n",
    "        if diff < 35:\n",
    "            diff = (diff / 35) ** 2 * max1\n",
    "        else:\n",
    "            diff = max2\n",
    "\n",
    "        if sign < 0:\n",
    "            return -diff\n",
    "        else:\n",
    "            return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T17:42:44.146164Z",
     "start_time": "2018-03-01T17:42:44.133018Z"
    }
   },
   "outputs": [],
   "source": [
    "class PolicyValueNetwork():\n",
    "    def __init__(self):\n",
    "        self._sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=24))\n",
    "        K.set_session(self._sess)\n",
    "        \n",
    "        self._model = load_model('AtaxxZero.h5')\n",
    "        print(\"successfully loaded two models\")\n",
    "           \n",
    "    def predict(self, feature_map, action_mask):        \n",
    "        return self._sess.run(self._model.outputs, feed_dict={self._model.inputs[0]: feature_map.reshape(-1, 6, 9, 9), \\\n",
    "                                self._model.inputs[1]: action_mask.reshape(-1, 792), K.learning_phase(): 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T17:55:00.572644Z",
     "start_time": "2018-03-01T17:54:59.902899Z"
    }
   },
   "outputs": [],
   "source": [
    "'''These methods are for normal Min max'''\n",
    "class MinMaxNormal():\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate(board, turn):\n",
    "        turn_no = 0\n",
    "        op_no = 0\n",
    "        # get no diff of turns\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                if board[r, c] == turn:\n",
    "                    turn_no += 1\n",
    "                elif board[r, c] == -turn:\n",
    "                    op_no += 1\n",
    "        return (turn_no - op_no)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_valid(board, turn, pos):\n",
    "        r = pos[0]\n",
    "        c = pos[1]\n",
    "        if board[r, c] != 0:\n",
    "            return False\n",
    "        else:\n",
    "            for dr in range(-2, 3):\n",
    "                for dc in range(-2, 3):\n",
    "                    new_r = r+dr\n",
    "                    new_c = c+dc\n",
    "                    if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and board[new_r, new_c] == turn:\n",
    "                        return True\n",
    "            return False \n",
    "\n",
    "    def next_move(self, board, turn):\n",
    "        next_moves = []\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                has_duplicate_move = False      # move within the radius of one of another friendly piece is called\n",
    "                if self.is_valid(board, turn, (r, c)): # duplicate move\n",
    "                    for dr in range(-2, 3):\n",
    "                        for dc in range(-2, 3):\n",
    "                            new_r = r+dr\n",
    "                            new_c = c+dc\n",
    "                            if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and board[new_r, new_c] == turn:\n",
    "                                if abs(dr) <= 1 and abs(dc) <=1:\n",
    "                                    if board[new_r, new_c] == turn and not has_duplicate_move:\n",
    "                                        dup_move = ((new_r, new_c), (r, c))\n",
    "                                        has_duplicate_move = True\n",
    "                                        yield dup_move\n",
    "                                elif board[new_r, new_c] == turn:\n",
    "                                    cur_move = ((new_r, new_c), (r, c))\n",
    "                                    yield cur_move\n",
    "                                else:\n",
    "                                    continue\n",
    "\n",
    "    def has_next_move(self, board, turn):\n",
    "        try:\n",
    "            next(self.next_move(board, turn))\n",
    "            return True\n",
    "        except StopIteration:\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def move_to(board, turn, pos0, pos1):\n",
    "        x0 = pos0[0]\n",
    "        y0 = pos0[1]\n",
    "        x1 = pos1[0]\n",
    "        y1 = pos1[1]\n",
    "\n",
    "        board = board.copy()\n",
    "        board[x1, y1] = turn\n",
    "        if abs(x0 - x1) > 1 or abs(y0 - y1) > 1:   # jump move\n",
    "            board[x0, y0] = 0\n",
    "\n",
    "        for dr in range(-1, 2):                  # infection mode!!!!\n",
    "            for dc in range(-1, 2):\n",
    "                if x1+dr >= 0 and y1+dc >= 0 and x1+dr < 7 and y1+dc < 7:\n",
    "                    if board[x1+dr, y1+dc] == -turn:  # convert any piece of the opponent to 'turn'\n",
    "                        board[x1+dr, y1+dc] = turn\n",
    "        return board\n",
    "\n",
    "    def min_max(self, board, turn, target_turn, depth=3, alpha=-100, beta=100, is_max=True, is_root=True):\n",
    "        '''A recursive alpha beta pruning min_max function\n",
    "        return: board evaluation, chosen move\n",
    "        NB. for board evaluation, if the searching was pruned, it will return 100 for a minimizer and -100 for a maximizer'''\n",
    "        if is_root:\n",
    "            best_moves = []\n",
    "        else:\n",
    "            best_move = ((0, 0), (0, 0))\n",
    "\n",
    "        if depth == 0 or not self.has_next_move(board, turn): # start to do pruning and selecting once the recursion reaches the end\n",
    "            result = self.evaluate(board, target_turn)\n",
    "            return result, None\n",
    "        else:\n",
    "            if is_max:\n",
    "                alpha = -100\n",
    "            else:\n",
    "                beta = 100\n",
    "\n",
    "            for move in self.next_move(board, turn):\n",
    "                result, _ = self.min_max(self.move_to(board, turn, move[0], move[1]), \\\n",
    "                                    -turn, target_turn, depth-1, alpha, beta, not is_max, False)\n",
    "                # prun the searching tree or update alpha and beta respectively\n",
    "                if is_max:\n",
    "                    if result >= beta:\n",
    "                        return 100, None\n",
    "                    elif result > alpha:\n",
    "                        alpha = result\n",
    "                        if is_root:\n",
    "                            best_moves = [move]\n",
    "                        else:\n",
    "                            best_move = move\n",
    "                    elif result == alpha and is_root:\n",
    "                        best_moves.append(move)\n",
    "                else:\n",
    "                    if result <= alpha:\n",
    "                        return -100, None\n",
    "                    elif result < beta:\n",
    "                        beta = result\n",
    "                        if is_root:\n",
    "                            best_moves = [move]\n",
    "                        else:\n",
    "                            best_move = move\n",
    "                    elif result == beta and is_root:\n",
    "                        best_moves.append(move)\n",
    "            if is_max:\n",
    "                if is_root:\n",
    "                    return alpha, choice(best_moves)\n",
    "                else:\n",
    "                    return alpha, best_move\n",
    "            else:\n",
    "                if is_root:\n",
    "                    return beta, choice(best_moves)\n",
    "                else:\n",
    "                    return beta, best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T22:00:40.653134Z",
     "start_time": "2018-03-01T22:00:39.186173Z"
    }
   },
   "outputs": [],
   "source": [
    "'''These methods are for Min max with ataxxzero'''\n",
    "class MinMaxZero():\n",
    "    def __init__(self):\n",
    "        self._evaluator = PolicyValueNetwork()\n",
    "        self._policy_dict = self.get_policy_dict()\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_policy_dict():\n",
    "        '''Get the relation between policy no. and policy'''\n",
    "        index=0\n",
    "        policy_dict = {}\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                for dr in range(-2, 3):\n",
    "                    for dc in range(-2, 3):\n",
    "                        new_r = r + dr\n",
    "                        new_c = c + dc\n",
    "                        if (dr != 0 or dc != 0) and (new_r < 7 and new_r >= 0) and (new_c < 7 and new_c >= 0):\n",
    "                            policy_dict[((r, c), (new_r, new_c))] = index\n",
    "                            index += 1\n",
    "        return policy_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def get_feature_map(board, turn, pre_move):\n",
    "        out = np.zeros((6, 9, 9), dtype=np.int8)\n",
    "        # define 1 edge\n",
    "\n",
    "        # edge\n",
    "        out[0, 0, :] = 1\n",
    "        out[0, 8, :] = 1\n",
    "        out[0, :, 0] = 1\n",
    "        out[0, :, 8] = 1\n",
    "\n",
    "        # my pieces\n",
    "        out[1, 1:8, 1:8] = (board == turn)\n",
    "\n",
    "        # op pieces\n",
    "        out[2, 1:8, 1:8] = (board == -turn)\n",
    "        \n",
    "        # last move\n",
    "        if not pre_move is None:               \n",
    "            out[3, pre_move[0][0]+1, pre_move[0][1]+1] = 1\n",
    "            out[4, pre_move[1][0]+1, pre_move[1][1]+1] = 1\n",
    "\n",
    "        # whose first\n",
    "        if turn == -1:\n",
    "            out[5, ...] = 1\n",
    "        return out\n",
    "    \n",
    "    def evaluate(self, feature_map, action_mask, turn, target_turn):\n",
    "        result = self._evaluator.predict(feature_map, action_mask)\n",
    "        p = result[0][0]\n",
    "        if turn == target_turn:\n",
    "            q = result[1][0]\n",
    "        else:\n",
    "            q = -result[1][0]\n",
    "        return p, q\n",
    "\n",
    "    @staticmethod\n",
    "    def is_valid(board, turn, pos):\n",
    "        r = pos[0]\n",
    "        c = pos[1]\n",
    "        if board[r, c] != 0:\n",
    "            return\n",
    "        else:\n",
    "            for dr in range(-2, 3):\n",
    "                for dc in range(-2, 3):\n",
    "                    new_r = r+dr\n",
    "                    new_c = c+dc\n",
    "                    try:\n",
    "                        assert new_r >= 0 and new_c >= 0 and board[new_r, new_c] == turn\n",
    "                        yield new_r, new_c, dr, dc\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    def get_moves(self, board, turn):\n",
    "        next_moves = []\n",
    "        dup_moves = []\n",
    "        action_mask = np.zeros(792, np.int8)\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                has_duplicate_move = False      # move within the radius of one of another friendly piece is called\n",
    "                for new_r, new_c, dr, dc in self.is_valid(board, turn, (r, c)): # duplicate move\n",
    "                    cur_move = ((new_r, new_c), (r, c))\n",
    "                    # update action mask\n",
    "                    action_mask[self._policy_dict[cur_move]] = 1\n",
    "                    if abs(dr) <= 1 and abs(dc) <=1:\n",
    "                        if not has_duplicate_move:\n",
    "                            has_duplicate_move = True\n",
    "                            next_moves.append(cur_move)\n",
    "                    else:\n",
    "                        next_moves.append(cur_move)\n",
    "\n",
    "        return next_moves, action_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def move_to(board, turn, pos0, pos1):\n",
    "        x0 = pos0[0]\n",
    "        y0 = pos0[1]\n",
    "        x1 = pos1[0]\n",
    "        y1 = pos1[1]\n",
    "\n",
    "        board = board.copy()\n",
    "        board[x1, y1] = turn\n",
    "        if abs(x0 - x1) > 1 or abs(y0 - y1) > 1:   # jump move\n",
    "            board[x0, y0] = 0\n",
    "\n",
    "        for dr in range(-1, 2):                  # infection mode!!!!\n",
    "            for dc in range(-1, 2):\n",
    "                if x1+dr >= 0 and y1+dc >= 0 and x1+dr < 7 and y1+dc < 7:\n",
    "                    if board[x1+dr, y1+dc] == -turn:  # convert any piece of the opponent to 'turn'\n",
    "                        board[x1+dr, y1+dc] = turn\n",
    "        return board\n",
    "\n",
    "    @staticmethod\n",
    "    def display_move_prob(move_prob):\n",
    "        for move, prob in move_prob:\n",
    "            print(move, prob)\n",
    "    \n",
    "    def min_max(self, board, turn, target_turn, depth=3, alpha=-100, beta=100, is_max=True, is_root=True, \\\n",
    "                pre_move=None, t_lim=1):\n",
    "        '''A recursive alpha beta pruning min_max function\n",
    "        return: board evaluation, chosen move\n",
    "        NB. for board evaluation, if the searching was pruned, it will return 100 for a minimizer and -100 for a maximizer'''\n",
    "        if is_root:\n",
    "            best_moves = []\n",
    "            self._start = time.time()\n",
    "        else:\n",
    "            best_move = ((0, 0), (0, 0))\n",
    "        \n",
    "        # get next moves\n",
    "        next_moves, action_mask = self.get_moves(board, turn)\n",
    "        # stop searching if the game is over\n",
    "        if len(next_moves) == 0:\n",
    "            if (board == target_turn).sum() - (board == -target_turn).sum() > 0:\n",
    "                return 1, None\n",
    "            else:\n",
    "                return -1, None\n",
    "        else: # otherwise calculate p and q and do the NN pruned minmax searching\n",
    "            feature_map = self.get_feature_map(board, turn, pre_move)\n",
    "            p, q = self.evaluate(feature_map, action_mask, turn, target_turn)\n",
    "            \n",
    "        if depth == 0: # once the recursion reaches the end, return the leaf node value\n",
    "            return q, None\n",
    "        else:\n",
    "            # generate move corresponding p list\n",
    "            move_prob = []\n",
    "            all_prob = 0.0\n",
    "            for move in next_moves:\n",
    "                prob = p[self._policy_dict[move]]\n",
    "                move_prob.append((move, prob))\n",
    "                all_prob += prob\n",
    "            move_prob = sorted(move_prob, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            if is_max:\n",
    "                alpha = -100\n",
    "            else:\n",
    "                beta = 100\n",
    "\n",
    "            sum_prob = 0.0\n",
    "            counter = 0\n",
    "            counter_thresh = len(move_prob) / 10.0\n",
    "            prob_thresh = all_prob * 0.95\n",
    "            # display_move_prob(move_prob)\n",
    "            for move, prob in move_prob:\n",
    "                sum_prob += prob\n",
    "                counter += 1\n",
    "                # do searching\n",
    "                result, _ = self.min_max(self.move_to(board, turn, move[0], move[1]), \\\n",
    "                                    -turn, target_turn, depth-1, alpha, beta, not is_max, False, move, t_lim)\n",
    "                # prun the searching tree or update alpha and beta respectively\n",
    "                if is_max:\n",
    "                    if result >= beta:\n",
    "                        return 100, None\n",
    "                    elif result > alpha:\n",
    "                        alpha = result\n",
    "                        if is_root:\n",
    "                            best_moves = [move]\n",
    "                        else:\n",
    "                            best_move = move\n",
    "                    elif result == alpha and is_root:\n",
    "                        best_moves.append(move)\n",
    "                else:\n",
    "                    if result <= alpha:\n",
    "                        return -100, None\n",
    "                    elif result < beta:\n",
    "                        beta = result\n",
    "                        if is_root:\n",
    "                            best_moves = [move]\n",
    "                        else:\n",
    "                            best_move = move\n",
    "                    elif result == beta and is_root:\n",
    "                        best_moves.append(move)\n",
    "\n",
    "                if (sum_prob >= prob_thresh and counter >= counter_thresh) or time.time() - self._start >= t_lim:\n",
    "                    # print(counter, counter_thresh, prob_thresh)\n",
    "                    break\n",
    "\n",
    "            if is_max:\n",
    "                if is_root:\n",
    "                    return alpha, choice(best_moves)\n",
    "                else:\n",
    "                    return alpha, best_move\n",
    "            else:\n",
    "                if is_root:\n",
    "                    return beta, choice(best_moves)\n",
    "                else:\n",
    "                    return beta, best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T22:00:48.451885Z",
     "start_time": "2018-03-01T22:00:42.053589Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded two models\n",
      "zero chose color -1\n",
      "minmax zero, with depth 3 move takes time:  0.6975622177124023\n",
      "minmax normal, with depth 2 move takes time:  0.03849482536315918\n",
      "minmax zero, with depth 3 move takes time:  0.2246861457824707\n",
      "minmax normal, with depth 2 move takes time:  0.04814887046813965\n",
      "minmax zero, with depth 3 move takes time:  0.44536304473876953\n",
      "minmax normal, with depth 2 move takes time:  0.1405189037322998\n",
      "minmax zero, with depth 3 move takes time:  0.4266970157623291\n",
      "minmax normal, with depth 2 move takes time:  0.18750500679016113\n",
      "minmax zero, with depth 3 move takes time:  0.2254009246826172\n",
      "minmax normal, with depth 2 move takes time:  0.12983989715576172\n",
      "minmax zero, with depth 3 move takes time:  0.3361837863922119\n",
      "minmax normal, with depth 2 move takes time:  0.11101102828979492\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-0b2ffba84dbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminmax_zero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZ_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_move\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_move\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mspan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"minmax zero, with depth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"move takes time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-42cb3ede35ee>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(self, board, turn, target_turn, depth, alpha, beta, is_max, is_root, pre_move, t_lim)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# do searching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                     \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-42cb3ede35ee>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(self, board, turn, target_turn, depth, alpha, beta, is_max, is_root, pre_move, t_lim)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# do searching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                     \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-42cb3ede35ee>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(self, board, turn, target_turn, depth, alpha, beta, is_max, is_root, pre_move, t_lim)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# do searching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                     \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-42cb3ede35ee>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(self, board, turn, target_turn, depth, alpha, beta, is_max, is_root, pre_move, t_lim)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# otherwise calculate p and q and do the NN pruned minmax searching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mfeature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_move\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# once the recursion reaches the end, return the leaf node value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-42cb3ede35ee>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, feature_map, action_mask, turn, target_turn)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mturn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-48b75d7afd22>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feature_map, action_mask)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maction_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m792\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "minmax_zero = MinMaxZero()\n",
    "minmax_normal = MinMaxNormal()\n",
    "N = 20\n",
    "N_D = 2\n",
    "Z_D = 3\n",
    "zero_win = 0\n",
    "time_zero = []\n",
    "time_normal = []\n",
    "for _ in range(N):\n",
    "    steps = 0\n",
    "    a = Ataxx()\n",
    "    turn = -1\n",
    "    zero_turn = choice([-1, 1])\n",
    "    print(\"zero chose color\", zero_turn)\n",
    "    best_move = None\n",
    "    while True:\n",
    "        steps += 1\n",
    "        #a.plot()\n",
    "        if turn != zero_turn:\n",
    "            s = time.time()\n",
    "            # _, best_move = minmax_normal.min_max(a.data, turn, turn, depth=N_D)\n",
    "            _, best_move = minmax_zero.min_max(a.data, turn, turn, depth=N_D, pre_move=best_move, t_lim=1)\n",
    "            span = time.time() - s\n",
    "            print(\"minmax normal, with depth\", N_D, \"move takes time: \", span)\n",
    "            if steps > 10 and steps < 60:\n",
    "                time_normal.append(span)\n",
    "        else:\n",
    "            s = time.time()\n",
    "            _, best_move = minmax_zero.min_max(a.data, turn, turn, depth=Z_D, pre_move=best_move, t_lim=1)\n",
    "            span = time.time() - s\n",
    "            print(\"minmax zero, with depth\", Z_D, \"move takes time: \", span)\n",
    "            if steps > 10 and steps < 60:\n",
    "                time_zero.append(span)\n",
    "        a.move_to(turn, best_move[0], best_move[1])\n",
    "        turn = -turn\n",
    "        result = a.evaluate(zero_turn, turn)\n",
    "        if result == 1:\n",
    "            print(\"\\n\\n\\n\\n minmax zero win!! \\n\\n\\n\\n\")\n",
    "            zero_win += 1\n",
    "            break\n",
    "        elif result == -1:\n",
    "            print(\"\\n\\n\\n\\n minmax normal win!! \\n\\n\\n\\n\")\n",
    "            break\n",
    "print(\"In the previous \", N, \" rounds, zero win ratio is: \", float(zero_win) / float(N))\n",
    "time_zero = np.array(time_zero)\n",
    "time_normal = np.array(time_normal)\n",
    "print(\"On average, for minmax normal with depth\", N_D, \\\n",
    "      \", each move takes time: \", time_normal.mean(),\\\n",
    "      \"max time elapsed:\", time_normal.max())\n",
    "print(\"On average, for minmax zero with depth\", Z_D, \\\n",
    "      \", each move takes time: \", time_zero.mean(),\\\n",
    "      \"max time elapsed:\", time_zero.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T22:03:24.486141Z",
     "start_time": "2018-03-01T22:03:20.330510Z"
    }
   },
   "outputs": [],
   "source": [
    "a = Ataxx()\n",
    "%lprun -f minmax_zero.is_valid _, best_move = minmax_zero.min_max(a.data, turn, turn, depth=6, pre_move=best_move, t_lim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
