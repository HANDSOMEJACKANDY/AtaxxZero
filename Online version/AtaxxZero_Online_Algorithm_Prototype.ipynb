{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T16:44:15.314477Z",
     "start_time": "2018-02-28T16:44:13.602724Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import importlib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from math import sqrt, log, exp\n",
    "from numpy import unravel_index\n",
    "from random import choice, random, sample\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import Sequential, Model, load_model\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "K.set_image_dim_ordering('th')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T16:44:16.176126Z",
     "start_time": "2018-02-28T16:44:16.152636Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_policy_dict_list():\n",
    "    '''Get the relation between policy no. and policy'''\n",
    "    index=0\n",
    "    policy_dict = {}\n",
    "    policy_list = []\n",
    "    for r in range(7):\n",
    "        for c in range(7):\n",
    "            for dr in range(-2, 3):\n",
    "                for dc in range(-2, 3):\n",
    "                    new_r = r + dr\n",
    "                    new_c = c + dc\n",
    "                    if (dr != 0 or dc != 0) and (new_r < 7 and new_r >= 0) and (new_c < 7 and new_c >= 0):\n",
    "                        policy_dict[((r, c), (new_r, new_c))] = index\n",
    "                        policy_list.append(((r, c), (new_r, new_c)))\n",
    "                        index += 1\n",
    "    return policy_dict, policy_list\n",
    "\n",
    "policy_dict, policy_list = get_policy_dict_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:56:12.082301Z",
     "start_time": "2018-02-28T17:56:09.716299Z"
    }
   },
   "outputs": [],
   "source": [
    "class Ataxx:\n",
    "    def __init__(self, board=None):\n",
    "        if board is None:                  # if there is no initialization given\n",
    "            self.data = np.zeros((7, 7), dtype=np.int8)   # then generate a board with starting init, and black(-1) takes first turn\n",
    "            self.data[0, 0] = -1           \n",
    "            self.data[6, 6] = -1\n",
    "            self.data[0, 6] = 1\n",
    "            self.data[6, 0] = 1\n",
    "        else:\n",
    "            self.data = board.copy()\n",
    "            \n",
    "    def reset(self, board=None):\n",
    "        if board is None:\n",
    "            self.data = np.zeros((7, 7), dtype=np.int8)\n",
    "            self.data[0, 0] = -1           \n",
    "            self.data[6, 6] = -1\n",
    "            self.data[0, 6] = 1\n",
    "            self.data[6, 0] = 1\n",
    "        else:\n",
    "            self.data = board.copy()\n",
    "        \n",
    "    def get_feature_map(self, turn, move):\n",
    "        out = np.zeros((6, 9, 9), dtype=np.int8)\n",
    "        # define 1 edge\n",
    "        \n",
    "        # edge\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if j == 0 or j == 8 or k == 0 or k == 8:\n",
    "                    out[0, j, k] = 1\n",
    "         \n",
    "        # my pieces\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if j > 0 and j < 8 and k > 0 and k < 8:\n",
    "                    if self.data[j-1, k-1] == turn:\n",
    "                        out[1, j, k] = 1\n",
    "        \n",
    "        # op pieces\n",
    "        for j in range(9):\n",
    "            for k in range(9):\n",
    "                if j > 0 and j < 8 and k > 0 and k < 8:\n",
    "                    if self.data[j-1, k-1] == -turn:\n",
    "                        out[2, j, k] = 1\n",
    "         \n",
    "        # last move\n",
    "        if not move is None:               \n",
    "            out[3, move[0][0]+1, move[0][1]+1] = 1\n",
    "            out[4, move[1][0]+1, move[1][1]+1] = 1\n",
    "            \n",
    "        # whose first\n",
    "        if turn == -1:\n",
    "            for j in range(9):\n",
    "                for k in range(9):\n",
    "                    out[5, j, k] = 1\n",
    "        return np.array(out)\n",
    "    \n",
    "    def plot(self, is_next_move=False, turn=None):                        # plot the board\n",
    "        image = self.data.copy()\n",
    "        if is_next_move:\n",
    "            if turn not in [-1, 1]:\n",
    "                raise ValueError(\"Turn must be -1 or 1, or Must input a turn for next moves\")\n",
    "            else:\n",
    "                next_moves = self.get_moves(turn)\n",
    "                if len(next_moves) == 0:\n",
    "                    raise ValueError(\"Game is over already\")\n",
    "                next_pos = list(zip(*next_moves))[1]\n",
    "                for pos in next_pos:\n",
    "                    image[pos] = turn / 2\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.xticks(range(7), range(7))\n",
    "        plt.yticks(range(7), range(7))\n",
    "        plt.show()\n",
    "        \n",
    "    def get_greedy_move(self, turn, moves=None):\n",
    "        best_score = -50\n",
    "        # get all possible moves if not provided\n",
    "        if moves is None:\n",
    "            moves, corr_dict, _, _ = self.get_moves(turn, return_node_info=True)\n",
    "            for item in corr_dict:\n",
    "                moves.append(item)\n",
    "        \n",
    "        if len(moves) == 0:\n",
    "            raise ValueError('No Possible Moves')\n",
    "        \n",
    "        best_moves = []\n",
    "        # calculate greedy move\n",
    "        for (x0, y0), (x1, y1) in moves:\n",
    "            tmp_score = 0\n",
    "            if abs(x0-x1) <= 1 and abs(y0-y1) <= 1:\n",
    "                tmp_score += 1\n",
    "            for dr in range(-1, 2):\n",
    "                for dc in range(-1, 2):\n",
    "                    try:\n",
    "                        if x1+dr >= 0 and y1+dc >= 0:\n",
    "                            tmp_score += self.data[x1+dr, y1+dc] == -turn\n",
    "                    except:\n",
    "                        pass\n",
    "            if tmp_score > best_score:\n",
    "                best_moves = [((x0, y0), (x1, y1))]\n",
    "                best_score = tmp_score\n",
    "            elif tmp_score == best_score:\n",
    "                best_moves.append(((x0, y0), (x1, y1)))\n",
    "        return choice(best_moves)\n",
    "                \n",
    "    def is_valid(self, turn, pos):\n",
    "        r = pos[0]\n",
    "        c = pos[1]\n",
    "        if self.data[r, c] != 0:\n",
    "            return False\n",
    "        else:\n",
    "            for dr in range(-2, 3):\n",
    "                for dc in range(-2, 3):\n",
    "                    new_r = r+dr\n",
    "                    new_c = c+dc\n",
    "                    if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and self.data[new_r, new_c] == turn:\n",
    "                        return True\n",
    "            return False \n",
    "        \n",
    "    def get_moves(self, turn, return_node_info=False):\n",
    "        action_mask = np.zeros(792, dtype=np.int8)\n",
    "        next_moves = []\n",
    "        corr_dict = {}\n",
    "        children_dict = {}\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                has_duplicate_move = False      # move within the radius of one of another friendly piece is called\n",
    "                if self.is_valid(turn, (r, c)): # duplicate move\n",
    "                    for dr in range(-2, 3):\n",
    "                        for dc in range(-2, 3):\n",
    "                            new_r = r+dr\n",
    "                            new_c = c+dc\n",
    "                            if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and self.data[new_r, new_c] == turn:\n",
    "                                if abs(dr) <= 1 and abs(dc) <=1:\n",
    "                                    if has_duplicate_move: \n",
    "                                        cur_move = ((new_r, new_c), (r, c))\n",
    "                                        corr_dict[cur_move] = dup_move\n",
    "                                        # update action mask\n",
    "                                        if return_node_info: \n",
    "                                            action_mask[policy_dict[cur_move]] = 1\n",
    "                                    elif self.data[new_r, new_c] == turn:\n",
    "                                        dup_move = ((new_r, new_c), (r, c))\n",
    "                                        next_moves.append(dup_move) \n",
    "                                        has_duplicate_move = True\n",
    "                                        # preparing children nodes and action mask\n",
    "                                        if return_node_info: \n",
    "                                            children_dict[dup_move] = None\n",
    "                                            action_mask[policy_dict[dup_move]] = 1\n",
    "                                elif self.data[new_r, new_c] == turn:\n",
    "                                    cur_move = ((new_r, new_c), (r, c))\n",
    "                                    next_moves.append(cur_move) \n",
    "                                    # preparing children nodes and action mask\n",
    "                                    if return_node_info:\n",
    "                                        children_dict[cur_move] = None\n",
    "                                        action_mask[policy_dict[cur_move]] = 1\n",
    "                                else:\n",
    "                                    continue\n",
    "        if return_node_info:\n",
    "            return next_moves, corr_dict, children_dict, np.array(action_mask)\n",
    "        else:\n",
    "            return next_moves\n",
    "        \n",
    "    def move_to(self, turn, pos0, pos1):\n",
    "        x0 = pos0[0]\n",
    "        y0 = pos0[1]\n",
    "        x1 = pos1[0]\n",
    "        y1 = pos1[1]\n",
    "        \n",
    "        if not self.is_valid(turn, pos1):\n",
    "            raise ValueError(\"This move: \" + str((pos0, pos1)) + \" of turn: \" + str(turn) + \" is invalid\") \n",
    "        elif self.data[x0, y0] != turn:\n",
    "            raise ValueError(\"The starting position is not your piece\")\n",
    "        else:\n",
    "            self.data[x1, y1] = turn\n",
    "            if abs(x0 - x1) > 1 or abs(y0 - y1) > 1:   # jump move\n",
    "                self.data[x0, y0] = 0\n",
    "\n",
    "            for dr in range(-1, 2):                  # infection mode!!!!\n",
    "                for dc in range(-1, 2):\n",
    "                    if x1+dr >= 0 and y1+dc >= 0 and x1+dr < 7 and y1+dc < 7:\n",
    "                        if self.data[x1+dr, y1+dc] == -turn:  # convert any piece of the opponent to 'turn'\n",
    "                            self.data[x1+dr, y1+dc] = turn\n",
    "    \n",
    "    def evaluate(self, turn, this_turn, max_score=1, min_score=0.001):\n",
    "        turn_no=0\n",
    "        op_no=0\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                if self.data[r, c] == turn:\n",
    "                    turn_no += 1\n",
    "                elif self.data[r, c] == -turn:\n",
    "                    op_no += 1\n",
    "        if len(self.get_moves(this_turn)) == 0:# if one of them can no longer move, count and end\n",
    "            if turn_no > op_no:\n",
    "                return max_score\n",
    "            else:\n",
    "                return -max_score\n",
    "        else:\n",
    "            value = turn_no - op_no\n",
    "        return value * min_score\n",
    "    \n",
    "    @staticmethod    \n",
    "    def get_manual_q(turn, board):\n",
    "        '''consider linear growth of win prob with regard to n_diff\n",
    "        when diff >= 10, the slope grow a bit\n",
    "        when diff >= 35, consider win prob close to 1 or -1\n",
    "        ''' \n",
    "        turn_no = 0\n",
    "        op_no = 0\n",
    "        max1=0.9\n",
    "        max2=0.95\n",
    "        # get no diff of turns\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                if board[r, c] == turn:\n",
    "                    turn_no += 1\n",
    "                elif board[r, c] == -turn:\n",
    "                    op_no += 1\n",
    "        diff = turn_no - op_no\n",
    "        if abs(diff) > 30:\n",
    "            return diff / abs(diff)\n",
    "        else:\n",
    "            return diff / 30\n",
    "        \n",
    "        # ignore the rest for now\n",
    "        sign = diff\n",
    "        diff = abs(diff)\n",
    "        if diff < 35:\n",
    "            diff = (diff / 35) ** 2 * max1\n",
    "        else:\n",
    "            diff = max2\n",
    "\n",
    "        if sign < 0:\n",
    "            return -diff\n",
    "        else:\n",
    "            return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:56:13.365470Z",
     "start_time": "2018-02-28T17:56:12.693291Z"
    }
   },
   "outputs": [],
   "source": [
    "'''These methods are for Min max'''\n",
    "def evaluate(board, turn):\n",
    "    turn_no = 0\n",
    "    op_no = 0\n",
    "    # get no diff of turns\n",
    "    for r in range(7):\n",
    "        for c in range(7):\n",
    "            if board[r, c] == turn:\n",
    "                turn_no += 1\n",
    "            elif board[r, c] == -turn:\n",
    "                op_no += 1\n",
    "    return (turn_no - op_no)\n",
    "        \n",
    "def is_valid(board, turn, pos):\n",
    "    r = pos[0]\n",
    "    c = pos[1]\n",
    "    if board[r, c] != 0:\n",
    "        return False\n",
    "    else:\n",
    "        for dr in range(-2, 3):\n",
    "            for dc in range(-2, 3):\n",
    "                new_r = r+dr\n",
    "                new_c = c+dc\n",
    "                if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and board[new_r, new_c] == turn:\n",
    "                    return True\n",
    "        return False \n",
    "    \n",
    "\n",
    "def next_move(board, turn):\n",
    "    next_moves = []\n",
    "    for r in range(7):\n",
    "        for c in range(7):\n",
    "            has_duplicate_move = False      # move within the radius of one of another friendly piece is called\n",
    "            if is_valid(board, turn, (r, c)): # duplicate move\n",
    "                for dr in range(-2, 3):\n",
    "                    for dc in range(-2, 3):\n",
    "                        new_r = r+dr\n",
    "                        new_c = c+dc\n",
    "                        if new_r >= 0 and new_c >= 0 and new_r < 7 and new_c < 7 and board[new_r, new_c] == turn:\n",
    "                            if abs(dr) <= 1 and abs(dc) <=1:\n",
    "                                if board[new_r, new_c] == turn and not has_duplicate_move:\n",
    "                                    dup_move = ((new_r, new_c), (r, c))\n",
    "                                    has_duplicate_move = True\n",
    "                                    yield dup_move\n",
    "                            elif board[new_r, new_c] == turn:\n",
    "                                cur_move = ((new_r, new_c), (r, c))\n",
    "                                yield cur_move\n",
    "                            else:\n",
    "                                continue\n",
    "\n",
    "def has_next_move(board, turn):\n",
    "    try:\n",
    "        next(next_move(board, turn))\n",
    "        return True\n",
    "    except StopIteration:\n",
    "        return False\n",
    "                                \n",
    "def move_to(board, turn, pos0, pos1):\n",
    "    x0 = pos0[0]\n",
    "    y0 = pos0[1]\n",
    "    x1 = pos1[0]\n",
    "    y1 = pos1[1]\n",
    "\n",
    "    if not is_valid(board, turn, pos1):\n",
    "        raise ValueError(\"This move: \" + str((pos0, pos1)) + \" of turn: \" + str(turn) + \" is invalid\") \n",
    "    elif board[x0, y0] != turn:\n",
    "        raise ValueError(\"The starting position is not your piece\")\n",
    "    else:\n",
    "        board = board.copy()\n",
    "        board[x1, y1] = turn\n",
    "        if abs(x0 - x1) > 1 or abs(y0 - y1) > 1:   # jump move\n",
    "            board[x0, y0] = 0\n",
    "\n",
    "        for dr in range(-1, 2):                  # infection mode!!!!\n",
    "            for dc in range(-1, 2):\n",
    "                if x1+dr >= 0 and y1+dc >= 0 and x1+dr < 7 and y1+dc < 7:\n",
    "                    if board[x1+dr, y1+dc] == -turn:  # convert any piece of the opponent to 'turn'\n",
    "                        board[x1+dr, y1+dc] = turn\n",
    "        return board\n",
    "    \n",
    "def min_max(board, turn, target_turn, depth=3, alpha=-100, beta=100, is_max=True, is_root=True):\n",
    "    '''A recursive alpha beta pruning min_max function\n",
    "    return: board evaluation, chosen move\n",
    "    NB. for board evaluation, if the searching was pruned, it will return 100 for a minimizer and -100 for a maximizer'''\n",
    "    if is_root:\n",
    "        best_moves = []\n",
    "    else:\n",
    "        best_move = ((0, 0), (0, 0))\n",
    "    \n",
    "    if depth == 0 or not has_next_move(board, turn): # start to do pruning and selecting once the recursion reaches the end\n",
    "        result = evaluate(board, target_turn)\n",
    "        return result, None\n",
    "    else:\n",
    "        if is_max:\n",
    "            alpha = -100\n",
    "        else:\n",
    "            beta = 100\n",
    "\n",
    "        for move in next_move(board, turn):\n",
    "            result, _ = min_max(move_to(board, turn, move[0], move[1]), \\\n",
    "                                -turn, target_turn, depth-1, alpha, beta, not is_max, False)\n",
    "            # prun the searching tree or update alpha and beta respectively\n",
    "            if is_max:\n",
    "                if result >= beta:\n",
    "                    return 100, None\n",
    "                elif result > alpha:\n",
    "                    alpha = result\n",
    "                    if is_root:\n",
    "                        best_moves = [move]\n",
    "                    else:\n",
    "                        best_move = move\n",
    "                elif result == alpha and is_root:\n",
    "                    best_moves.append(move)\n",
    "            else:\n",
    "                if result <= alpha:\n",
    "                    return -100, None\n",
    "                elif result < beta:\n",
    "                    beta = result\n",
    "                    if is_root:\n",
    "                        best_moves = [move]\n",
    "                    else:\n",
    "                        best_move = move\n",
    "                elif result == beta and is_root:\n",
    "                    best_moves.append(move)\n",
    "        if is_max:\n",
    "            if is_root:\n",
    "                return alpha, choice(best_moves)\n",
    "            else:\n",
    "                return alpha, best_move\n",
    "        else:\n",
    "            if is_root:\n",
    "                return beta, choice(best_moves)\n",
    "            else:\n",
    "                return beta, best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:56:16.277414Z",
     "start_time": "2018-02-28T17:56:13.412700Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 3 move takes time:  0.155440092086792\n",
      "depth 3 move takes time:  0.56014084815979\n",
      "depth 3 move takes time:  1.126162052154541\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-891399a21cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mspan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"move takes time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(board, turn, target_turn, depth, alpha, beta, is_max, is_root)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(board, turn, target_turn, depth, alpha, beta, is_max, is_root)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(board, turn, target_turn, depth, alpha, beta, is_max, is_root)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(board, turn, target_turn, depth, alpha, beta, is_max, is_root)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_next_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# start to do pruning and selecting once the recursion reaches the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(board, turn)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mturn_no\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mop_no\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mturn_no\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mop_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "D = 3\n",
    "greedy_win = 0\n",
    "time_avg = []\n",
    "for _ in range(N):\n",
    "    steps = 0\n",
    "    a = Ataxx()\n",
    "    turn = -1\n",
    "    greedy_turn = choice([-1, 1])\n",
    "    while True:\n",
    "        steps += 1\n",
    "        #a.plot()\n",
    "        if turn == greedy_turn:\n",
    "            best_move = a.get_greedy_move(turn)\n",
    "        else:\n",
    "            s = time.time()\n",
    "            _, best_move = min_max(a.data, turn, turn, depth=D)\n",
    "            span = time.time() - s\n",
    "            print(\"depth\", D, \"move takes time: \", time.time()-s)\n",
    "            if steps > 10 and steps < 60:\n",
    "                time_avg.append(span)\n",
    "        a.move_to(turn, best_move[0], best_move[1])\n",
    "        turn = -turn\n",
    "        result = a.evaluate(greedy_turn, turn)\n",
    "        if result == 1:\n",
    "            greedy_win += 1\n",
    "            break\n",
    "        elif result == -1:\n",
    "            break\n",
    "print(\"In the previous \", N, \" rounds, greedy win ratio is: \", float(greedy_win) / float(N))\n",
    "time_avg = np.array(time_avg)\n",
    "print(\"On average, for depth\", D, \\\n",
    "      \", each move takes time: \", time_avg.mean(),\\\n",
    "      \"max time elapsed:\", time_avg.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:56:16.282534Z",
     "start_time": "2018-02-28T17:56:13.099Z"
    }
   },
   "outputs": [],
   "source": [
    "class PolicyValueNetwork():\n",
    "    def __init__(self):\n",
    "        self._sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=24))\n",
    "        K.set_session(self._sess)\n",
    "        \n",
    "        self._model = load_model('AtaxxZero.h5')\n",
    "        print(\"successfully loaded two models\")\n",
    "           \n",
    "    def predict(self, feature_map, action_mask):        \n",
    "        return self._sess.run(self._model.outputs, feed_dict={self._model.inputs[0]: feature_map.reshape(-1, 6, 9, 9), \\\n",
    "                                self._model.inputs[1]: action_mask.reshape(-1, 792), K.learning_phase(): 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:56:16.287404Z",
     "start_time": "2018-02-28T17:56:13.926Z"
    }
   },
   "outputs": [],
   "source": [
    "def for_node(c, parent_n_visit, n_visit, p, q):\n",
    "    return c * p * sqrt(parent_n_visit + 1) / (n_visit + 1) - q / (n_visit + 1) \n",
    "\n",
    "def get_q(init_q, manual_q, mode):\n",
    "    '''Manual_q and init_q are both an estimation for the q value\n",
    "    It seems that considering init_q to be a rectification will not lead to good result'''\n",
    "    if mode == 0:\n",
    "        return manual_q\n",
    "    elif mode == 1:\n",
    "        return init_q\n",
    "    elif mode == 2:\n",
    "        return 0.75 * manual_q + 0.25 * init_q\n",
    "    elif mode == 3:\n",
    "        if abs(manual_q) >= 0.5:\n",
    "            return 0.5 * manual_q + 0.5 * init_q \n",
    "        elif abs(manual_q) >= 0.8:\n",
    "            return manual_q\n",
    "        elif abs(init_q) > 0.15:\n",
    "            return 0.2 * manual_q + 0.8 * init_q\n",
    "        elif abs(init_q) > 0.5:\n",
    "            return init_q\n",
    "        else:\n",
    "            return 0.4 * manual_q + 0.6 * init_q\n",
    "    elif mode == 4:\n",
    "        if abs(manual_q) >= 0.8:\n",
    "            return manual_q\n",
    "        elif abs(manual_q) >= 0.5:\n",
    "            return 0.5 * manual_q + 0.5 * init_q \n",
    "        else:\n",
    "            return init_q\n",
    "    else:\n",
    "        raise ValueError(\"Mode is not specified\")\n",
    "        \n",
    "class TreeNode():\n",
    "    def __init__(self, parent, p=0.0):\n",
    "        self._parent = parent\n",
    "        self._children = {} # a dictionary of action:node\n",
    "        self._corr_dict = {} # a dictionary for duplicated moves\n",
    "        self._n_visit = 0\n",
    "        # from the parent perspective\n",
    "        self._q = 0.0\n",
    "        self._manual_q = -5 # manually deviced q\n",
    "        self._init_q = -5 # learnt q\n",
    "        self._p = p\n",
    "        self._action_mask = None\n",
    "        self._feature_map = None\n",
    "        self._board = None\n",
    "        self._is_expanded = False\n",
    "        self._prev_move = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        out = \"_n_visit: {}, _q: {}, _p: {}, _children: \\n{}\".format(\\\n",
    "                self._n_visit, self._q, self._p, self._children)\n",
    "        return out\n",
    "    \n",
    "    def get_start_q(self, mode=0):\n",
    "        ''' Different mode means different q\n",
    "        mode 0: pure manual Q\n",
    "        mode 1: pure policy Q\n",
    "        mode 2: hybrid Q\n",
    "        '''\n",
    "        assert self._init_q != -5 and self._manual_q != -5\n",
    "        assert self._q == 0\n",
    "        self._q = get_q(self._init_q, self._manual_q, mode)\n",
    "    \n",
    "    def access_children(self, move):\n",
    "        try:\n",
    "            return self._children[move]\n",
    "        except:\n",
    "            return self._children[self._corr_dict[move]]\n",
    "    \n",
    "    def children_generator(self):\n",
    "        for move in self._children:\n",
    "            yield (move, self._children[move])\n",
    "        for move in self._corr_dict:\n",
    "            yield (move, self._children[self._corr_dict[move]])\n",
    "    \n",
    "    def update_all(self, t_v):\n",
    "        node = self\n",
    "        while not node is None: \n",
    "            node._q += t_v\n",
    "            node._n_visit += 1\n",
    "            node = node._parent\n",
    "            t_v = -t_v\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_search_value(parent, node, c):\n",
    "        # return values \n",
    "        try:\n",
    "            value = for_node(c, parent._n_visit, node._n_visit, node._p, node._q)\n",
    "        except:\n",
    "            print(parent)\n",
    "            print(node)\n",
    "            raise\n",
    "        return value\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_frequency_value(node):\n",
    "        try:\n",
    "            return node._n_visit\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def select(self, c):\n",
    "        best_node = [0, 0]\n",
    "        best_node[0], best_node[1] = max(self._children.items(), key=lambda node: self.get_search_value(self, node[1], c))\n",
    "        return best_node\n",
    "        \n",
    "    def get_action_mask(self):\n",
    "        # only generate the action mask once\n",
    "        if not self._action_mask is None:\n",
    "            return self._action_mask\n",
    "        else:\n",
    "            raise ValueError(\"No action mask, request failure\")\n",
    "    \n",
    "    def get_action_frequency_map(self, temp=1):\n",
    "        global policy_dict\n",
    "        out = np.zeros(len(policy_dict))\n",
    "        # record all the n_visit of each node\n",
    "        nodes = self.children_generator()\n",
    "        for node in nodes:\n",
    "            out[policy_dict[node[0]]] = (float(node[1]._n_visit) / 100) ** (1/temp)\n",
    "        # normalize the array\n",
    "        out /= out.sum()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:29:36.637966Z",
     "start_time": "2018-02-28T18:29:32.526853Z"
    }
   },
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "    def __init__(self, c=1, dep_lim=10, mode=1, game=None, turn=-1):\n",
    "        # slow_step means how many step we use to do typical mcts, after that we do fast play\n",
    "        self._c = c\n",
    "        self._dep_lim = dep_lim\n",
    "        if game is None:\n",
    "            self._game = Ataxx()\n",
    "        else:\n",
    "            self._game = game\n",
    "        self._turn = turn\n",
    "        # generate model\n",
    "        self._network = PolicyValueNetwork()\n",
    "        # determine which mode to use, default is 0, to switch mode, must do manually\n",
    "        self._mode = mode\n",
    "        # generate root and expand initially its children\n",
    "        self._root = TreeNode(None) # this one will move in self play mode\n",
    "        self.further_init(self._root, self._game, self._turn, get_p_array=True)\n",
    "        self._root_store = self._root # this is a backup for reset\n",
    "        \n",
    "        \n",
    "    def reset_root(self, move=None):\n",
    "        self._root = TreeNode(None) # this one will move in self play mode\n",
    "        self.further_init(self._root, self._game, self._turn, move, get_p_array=True)\n",
    "        self._root_store = self._root # this is a backup for reset\n",
    "        \n",
    "    def reset(self, left_space=45):\n",
    "        self._game.reset()\n",
    "        self._turn = -1\n",
    "        self._root = TreeNode(None)\n",
    "        \n",
    "        if left_space < 45:\n",
    "            steps = 0\n",
    "            is_terminal = False\n",
    "            result = 45\n",
    "            while not is_terminal and result > left_space:\n",
    "                if np.random.random() < 0.2: # 80 percent using greedy move\n",
    "                    best_move = choice(self._game.get_moves(self._turn))\n",
    "                    \n",
    "                else:\n",
    "                    best_move = self._game.get_greedy_move(self._turn)\n",
    "                    \n",
    "                self.make_a_move(best_move)\n",
    "                is_terminal = abs(self._game.evaluate(1, self._turn)) == 1\n",
    "                result = (np.array(self._game.data) == 0).sum()\n",
    "                steps += 1\n",
    "            if is_terminal:\n",
    "                print(\"reset failure, do reset again\")\n",
    "                self.reset(left_space)\n",
    "        self.reset_root()\n",
    "        try: # tell the _root which move led it here\n",
    "            self._root._move = best_move\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def plot_move_visit_freq(self):\n",
    "        nodes = sorted(self._root._children.items(), key=lambda node: self._root.get_frequency_value(node[1]), reverse=True)\n",
    "        p_sum = 0\n",
    "        for node in nodes:\n",
    "            try:\n",
    "                print(\"{}: n_v:{:>6d} q_all:{:+06.6f} q:{:+06.6f} q_m:{:+06.6f} p:{:06.6f}\"\\\n",
    "                      .format(node[0], node[1]._n_visit, -node[1]._q / (node[1]._n_visit + 1), \\\n",
    "                              -node[1]._init_q, -node[1]._manual_q, node[1]._p))\n",
    "                p_sum += node[1]._p\n",
    "            except:\n",
    "                pass\n",
    "        print(\"########################p_sum is: \", p_sum)\n",
    "                      \n",
    "    def get_next_move(self, q_best=True, rollout_times=100, t_lim=np.nan):\n",
    "        global policy_list\n",
    "        # do mcts\n",
    "        self.rollout(rollout_times, t_lim)\n",
    "        \n",
    "        if not q_best:\n",
    "            # return the most frequently visited move\n",
    "            index = np.argmax(self._root.get_action_frequency_map())\n",
    "            return policy_list[index]\n",
    "        else:\n",
    "            # return the highest q move\n",
    "            if self._root._n_visit > 8:\n",
    "                best_q = -5\n",
    "                best_move = None\n",
    "                for move, node in self._root._children.items():\n",
    "                    if node._n_visit > 5 and -node._q / (node._n_visit + 1) > best_q:\n",
    "                        best_q = -node._q / (node._n_visit + 1)\n",
    "                        best_move = move\n",
    "\n",
    "            if best_move is None or self._root._n_visit <= 8:\n",
    "                print(\"too few visits, use p policy\")\n",
    "                best_p = 0\n",
    "                best_move = None\n",
    "                for move, node in self._root._children.items():\n",
    "                    if node._p > best_p:\n",
    "                        best_p = node._p\n",
    "                        best_move = move\n",
    "            \n",
    "            return best_move\n",
    "            \n",
    "        \n",
    "    def make_a_move(self, next_move):\n",
    "        # move the root to next_move's root\n",
    "        if self._root._children == {}:\n",
    "            self._root = TreeNode(None)\n",
    "        elif type(self._root.access_children(next_move)) is np.float32: # the root may not be neccessarily expanded\n",
    "            self._root = TreeNode(None)\n",
    "        else:\n",
    "            self._root = self._root.access_children(next_move)\n",
    "            self._root._parent = None # necessary for updata_all\n",
    "        \n",
    "        # update the game board\n",
    "        self._game.move_to(self._turn, next_move[0], next_move[1])\n",
    "        self._turn = -self._turn\n",
    "      \n",
    "    def further_init(self, node, game, turn, prev_move=None, get_p_array=False):\n",
    "        global policy_dict, policy_list\n",
    "        node._prev_move = prev_move # tell which move led the node here\n",
    "        # preparing all children\n",
    "        new_moves, node._corr_dict, node._children, node._action_mask \\\n",
    "                                = game.get_moves(turn, return_node_info=True)\n",
    "        # if meet end of the game, generate manual q\n",
    "        if node._children == {}:\n",
    "            if node._manual_q == -5:\n",
    "                node._manual_q = game.get_manual_q(turn, game.data)\n",
    "            # quite tricky here dude, remember to look from the parent perspective\n",
    "            if node._manual_q > 0:\n",
    "                node._q = 1\n",
    "            else:\n",
    "                node._q = -1 \n",
    "            return\n",
    "        \n",
    "        # generate feature map\n",
    "        node._feature_map = game.get_feature_map(turn, prev_move)\n",
    "        node._board = game.data.copy()\n",
    "        # if required, generate p array and q, only if there are children\n",
    "        if get_p_array:\n",
    "            # generate policy prob array\n",
    "            out = self._network.predict(node._feature_map, node._action_mask)\n",
    "            p_array = out[0]\n",
    "            # give p to each child (float32)\n",
    "            for move in new_moves:\n",
    "                node._children[move] = p_array[0][policy_dict[move]]\n",
    "            # init node._q\n",
    "            node._init_q = out[1][0][0] \n",
    "            node._manual_q = game.get_manual_q(turn, game.data)\n",
    "            node.get_start_q(self._mode)\n",
    "        \n",
    "    def expand(self, node, game, turn):\n",
    "        global policy_dict, policy_list\n",
    "        \n",
    "        # if the node was not expanded, take that as a new root and further init it\n",
    "        if node._children == {} and node._q == 0:\n",
    "            self.further_init(node, game, turn, get_p_array=True)\n",
    "        # if end of game, quit expanding\n",
    "        if node._children == {}:\n",
    "            assert node._q != 0\n",
    "            return\n",
    "        \n",
    "        # update expanded state\n",
    "        node._is_expanded = True\n",
    "        \n",
    "        # if there are children\n",
    "        backup_board = game.data.copy() # warning, to backup a memoryview ndarray, use copy()\n",
    "        index_list = []\n",
    "        feature_map = []\n",
    "        action_mask = []\n",
    "        boards = []\n",
    "        for move in node._children:\n",
    "            tmp = node._children[move]\n",
    "            try:\n",
    "                assert type(tmp) is np.float32\n",
    "            except:\n",
    "                print(type(tmp))\n",
    "                raise\n",
    "            new_node = TreeNode(node, p=node._children[move])\n",
    "            game.move_to(turn,  move[0], move[1])\n",
    "            self.further_init(new_node, game, -turn, move, get_p_array=False)\n",
    "            node._children[move] = new_node\n",
    "            # prepare to calculate p for new_node only if it has children\n",
    "            if new_node._children != {}:\n",
    "                index_list.append(new_node)\n",
    "                feature_map.append(new_node._feature_map)\n",
    "                action_mask.append(new_node._action_mask)\n",
    "                boards.append(new_node._board)\n",
    "            # reset the gamer\n",
    "            game.reset(board=backup_board)\n",
    "        # if there are no more node that is expandable, quit\n",
    "        if len(index_list) == 0:\n",
    "            return\n",
    "        \n",
    "        # do batch prediction\n",
    "        # print(\"batch size:\", len(index_list))\n",
    "        feature_map = np.stack(feature_map, axis=0)\n",
    "        action_mask = np.stack(action_mask, axis=0)\n",
    "        out = self._network.predict(feature_map, action_mask)\n",
    "        # get batch manual q \n",
    "        boards = [game.get_manual_q(-turn, board) for board in boards]\n",
    "        # update the result to each child node\n",
    "        for i, child in enumerate(index_list):\n",
    "            # assign q\n",
    "            child._manual_q = boards[i] # neg for display use\n",
    "            child._init_q = out[1][i][0] # same as above\n",
    "            child.get_start_q(self._mode)\n",
    "            # assign p\n",
    "            assign_children(child._children, out[0][i])\n",
    "            \n",
    "\n",
    "    def rollout(self, rollout_times=100, t_lim=np.nan, t_min=2):\n",
    "        start = time.time()\n",
    "        for i in range(int(rollout_times*1.1)): \n",
    "            tmp_node = self._root\n",
    "            tmp_game = Ataxx(self._game.data)\n",
    "            tmp_turn = self._turn\n",
    "            # start mcts\n",
    "            step = 0\n",
    "            while True:\n",
    "                assert self._dep_lim > 0\n",
    "                if step < self._dep_lim:\n",
    "                    # expand the node only when it has never been expanded\n",
    "                    if tmp_node._is_expanded == False:\n",
    "                        self.expand(tmp_node, tmp_game, tmp_turn)\n",
    "\n",
    "                    # check if is leaf node, if so, update the whole tree\n",
    "                    if tmp_node._children == {}:\n",
    "                        t_v = tmp_node._q / (tmp_node._n_visit + 1)\n",
    "                        tmp_node.update_all(t_v)\n",
    "                        break\n",
    "                    else:\n",
    "                        # select a child and continue exploration\n",
    "                        next_move, next_node = tmp_node.select(self._c)\n",
    "                            \n",
    "                        # move to next move and next node\n",
    "                        tmp_game.move_to(tmp_turn, next_move[0], next_move[1])    \n",
    "                        tmp_node = next_node\n",
    "                        tmp_turn = -tmp_turn\n",
    "                else:\n",
    "                    t_v = tmp_node._q / (tmp_node._n_visit + 1)\n",
    "                    tmp_node.update_all(t_v)\n",
    "                    break\n",
    "                # update steps                                    \n",
    "                step += 1\n",
    "            cur_time = time.time() - start\n",
    "            if cur_time > t_lim * 0.999:\n",
    "                print(\"due to time lim, final rollout times: \", i, \"time elapsed: \", cur_time)\n",
    "                break\n",
    "            \n",
    "            if cur_time > t_min and i > rollout_times:\n",
    "                print(\"due to rollout lim, final rollout times: \", i, \"time elapsed: \", cur_time)\n",
    "                break\n",
    "                \n",
    "        \n",
    "    def testing_against_min_max(self, rounds=5, left_space=45, mm_dep=1, c=5, dep_lim=0, rollout_times=400, t_lim=6, verbose=True):\n",
    "        print(\"####               ####\")\n",
    "        print(\"#### start testing ####\")\n",
    "        test_start = time.time()\n",
    "        # record dep_lim and c for restoration\n",
    "        store_dep_lim = self._dep_lim\n",
    "        self._dep_lim = dep_lim\n",
    "        store_c = self._c\n",
    "        self._c = c\n",
    "        # recorder of game result\n",
    "        n_win = 0.0\n",
    "        win_steps = 0.0\n",
    "        lose_steps = 0.0\n",
    "        for r in range(rounds):\n",
    "            tmp_round_s = time.time()\n",
    "            # randomly init the game board if no left_space specified\n",
    "            self.reset(left_space)\n",
    "            # set up start turns\n",
    "            my_turn = choice([-1, 1])\n",
    "            if verbose:\n",
    "                print(\"round:\", r+1)\n",
    "                print(\"this game start with {} space left\".format(left_space))\n",
    "                print(\"self takes turn: \", my_turn)\n",
    "            # start the game\n",
    "            steps = 0\n",
    "            while abs(self._game.evaluate(1, self._turn)) != 1:\n",
    "                # plot the game board\n",
    "                if verbose:\n",
    "                    self._game.plot()\n",
    "                    tmp_s = time.time()\n",
    "                if self._turn == my_turn:\n",
    "                    best_move = self.get_next_move(q_best=True, rollout_times=rollout_times, t_lim=t_lim)\n",
    "                    if verbose:\n",
    "                        print(\"self turn\", my_turn)\n",
    "                        print(self.plot_move_visit_freq())\n",
    "                else:\n",
    "                    _, best_move = min_max(self._game.data, self._turn, self._turn, mm_dep)\n",
    "                    if verbose:\n",
    "                        print(\"greedy turn\", self._turn)\n",
    "                if verbose:\n",
    "                    print(\"this move takes time(s): \", time.time()-tmp_s)\n",
    "                    print(\"chosen move is \", best_move)\n",
    "\n",
    "                # synchronize steps and boards\n",
    "                self.make_a_move(best_move)\n",
    "                # update steps\n",
    "                steps += 1\n",
    "                if steps > 300:\n",
    "                    print(\"steps over 250, game skip\")\n",
    "                    break\n",
    "            if steps <= 300:\n",
    "                is_self_win = self._game.evaluate(my_turn, self._turn) == 1\n",
    "                if is_self_win:\n",
    "                    n_win += 1\n",
    "                    win_steps += steps\n",
    "                else:\n",
    "                    lose_steps += steps\n",
    "                if verbose:\n",
    "                    print(\"this round has steps: {}, time taken: {}, \\n\\n\\nself wins? {}\\n\\n\\n\".format(steps, time.time()-tmp_round_s, is_self_win))\n",
    "            else:\n",
    "                n_win += 0.5\n",
    "        # restore dep lim and c\n",
    "        self._dep_lim = store_dep_lim\n",
    "        self._c = store_c\n",
    "        \n",
    "        # output\n",
    "        print(\"testing took time: \", time.time()-test_start)\n",
    "        print(\"win steps: \", win_steps / (n_win + 1e-5), \"lose steps: \", lose_steps / (rounds - n_win + 1e-5))\n",
    "        print()\n",
    "        if n_win == 0:\n",
    "            return 0\n",
    "        return n_win / rounds\n",
    "    \n",
    "    def tester(self, mm_dep=1, Q=False, P=False, BOTH=False, mode=1, times=200, dep_lim=1, rollout_times=400, verbose=False, t_lim=6):\n",
    "        out = {}\n",
    "        mode_store = self._mode\n",
    "        self._mode = mode\n",
    "        print(\"mm_dep is: \", mm_dep)\n",
    "        if Q:\n",
    "            q_ratio = self.testing_against_min_max(\\\n",
    "                rounds=times, left_space=45, mm_dep=mm_dep, c=0, dep_lim=dep_lim, rollout_times=1, t_lim=t_lim, verbose=verbose)\n",
    "            print(\"\\n\\n\\n                        win ratio of Q is {} \\n\\n\\n\\n\\n\".format(q_ratio))\n",
    "            out['Q'] = q_ratio\n",
    "        if P:\n",
    "            p_ratio = self.testing_against_min_max(\\\n",
    "                rounds=times, left_space=45, mm_dep=mm_dep, c=1000000, dep_lim=dep_lim, rollout_times=1, t_lim=t_lim, verbose=verbose)\n",
    "            print(\"\\n\\n\\n                        win ratio of P is {} \\n\\n\\n\\n\\n\".format(p_ratio))\n",
    "            out['P'] = p_ratio\n",
    "        if BOTH: # multiple customizations for this one\n",
    "            both_ratio = self.testing_against_min_max(\\\n",
    "                rounds=int(times), left_space=45, mm_dep=mm_dep, c=self._c, dep_lim=dep_lim, rollout_times=rollout_times, t_lim=t_lim, verbose=verbose)\n",
    "            print(\"\\n\\n\\n                        win ratio of both is {} \\n\\n\\n\\n\\n\".format(both_ratio))\n",
    "            out['BOTH'] = both_ratio\n",
    "        self._mode = mode_store\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:29:53.950186Z",
     "start_time": "2018-02-28T18:29:52.426036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded two models\n"
     ]
    }
   ],
   "source": [
    "player = MCTS(c=10, dep_lim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T20:18:59.288455Z",
     "start_time": "2018-02-28T20:00:34.086569Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mm_dep is:  4\n",
      "####               ####\n",
      "#### start testing ####\n",
      "due to rollout lim, final rollout times:  201 time elapsed:  2.334890127182007\n",
      "due to rollout lim, final rollout times:  201 time elapsed:  2.4963479042053223\n",
      "due to rollout lim, final rollout times:  201 time elapsed:  2.4678149223327637\n",
      "due to rollout lim, final rollout times:  201 time elapsed:  4.353378057479858\n",
      "due to rollout lim, final rollout times:  201 time elapsed:  2.4262771606445312\n",
      "due to rollout lim, final rollout times:  206 time elapsed:  2.1254239082336426\n",
      "due to rollout lim, final rollout times:  206 time elapsed:  2.0996150970458984\n",
      "due to rollout lim, final rollout times:  206 time elapsed:  2.0063059329986572\n",
      "due to rollout lim, final rollout times:  206 time elapsed:  2.0216259956359863\n",
      "due to rollout lim, final rollout times:  206 time elapsed:  2.0129809379577637\n",
      "due to rollout lim, final rollout times:  206 time elapsed:  2.020231008529663\n",
      "due to rollout lim, final rollout times:  214 time elapsed:  2.000169038772583\n",
      "due to rollout lim, final rollout times:  206 time elapsed:  2.5096700191497803\n",
      "due to rollout lim, final rollout times:  206 time elapsed:  2.2927470207214355\n",
      "due to rollout lim, final rollout times:  210 time elapsed:  2.000746011734009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-7968d8414c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm_dep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBOTH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_lim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollout_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-b235743faec2>\u001b[0m in \u001b[0;36mtester\u001b[0;34m(self, mm_dep, Q, P, BOTH, mode, times, dep_lim, rollout_times, verbose, t_lim)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mBOTH\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# multiple customizations for this one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mboth_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting_against_min_max\u001b[0m\u001b[0;34m(\u001b[0m                \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmm_dep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmm_dep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_lim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdep_lim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollout_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrollout_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_lim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_lim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\\n                        win ratio of both is {} \\n\\n\\n\\n\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboth_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BOTH'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboth_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-b235743faec2>\u001b[0m in \u001b[0;36mtesting_against_min_max\u001b[0;34m(self, rounds, left_space, mm_dep, c, dep_lim, rollout_times, t_lim, verbose)\u001b[0m\n\u001b[1;32m    278\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_move_visit_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmm_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"greedy turn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_turn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(board, turn, target_turn, depth, alpha, beta, is_max, is_root)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(board, turn, target_turn, depth, alpha, beta, is_max, is_root)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(board, turn, target_turn, depth, alpha, beta, is_max, is_root)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(board, turn, target_turn, depth, alpha, beta, is_max, is_root)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                 \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;31m# prun the searching tree or update alpha and beta respectively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mmin_max\u001b[0;34m(board, turn, target_turn, depth, alpha, beta, is_max, is_root)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_next_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# start to do pruning and selecting once the recursion reaches the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_turn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-dda4faad4467>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(board, turn)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mturn_no\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "player.tester(mm_dep=3, BOTH=True, mode=1, times=10, dep_lim=2, rollout_times=200, verbose=False, t_lim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
